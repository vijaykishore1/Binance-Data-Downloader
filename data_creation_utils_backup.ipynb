{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./creating_arrays.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import talib\n",
    "import datetime\n",
    "import glob\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import inspect\n",
    "import talib\n",
    "import time\n",
    "import numpy as np\n",
    "import requests\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_monthly_data(month_array, symbol, chart_time):\n",
    "    #downloading monthly data\n",
    "    root_dir = Path.cwd()\n",
    "    # Create the new folder path\n",
    "    folder_path = Path(\n",
    "        download_dir) / f\"{symbol}-{chart_time}-monthly_data\"\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    count = 0\n",
    "    for month in month_array:\n",
    "        # Construct the link\n",
    "        link = f\"{BINANCE_MONTHLY_URL}{symbol}/{chart_time}/{symbol}-{chart_time}-{month}.zip\"\n",
    "        symbol_object = f\"{symbol}-{chart_time}-{month}.zip\"\n",
    "        # Create the file path\n",
    "        file_path = Path(folder_path) / symbol_object\n",
    "        if not file_path.exists():\n",
    "            try:\n",
    "                # Download the file\n",
    "                urllib.request.urlretrieve(link, file_path)\n",
    "                count += 1\n",
    "            except:\n",
    "                #                     print(f'{link} not found')\n",
    "                continue\n",
    "    if count > 0:\n",
    "        print (f\"Monthly Data Downloaded for {symbol},{chart_time}\")\n",
    "    else:\n",
    "        print (f\"you're already up to date for monthly data for {symbol},{chart_time}\")\n",
    "    \n",
    "\n",
    "    \n",
    "def download_daily_data(day_array, symbol, chart_time):\n",
    "    #downloading daily data\n",
    "    root_dir = Path.cwd()\n",
    "    # Create the new folder path\n",
    "    folder_path = Path(\n",
    "        download_dir) / f\"{symbol}-{chart_time}-daily_data\"\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    count = 0\n",
    "    for day in day_array:\n",
    "        # Construct the link\n",
    "        link = f\"{BINANCE_DAILY_URL}{symbol}/{chart_time}/{symbol}-{chart_time}-{day}.zip\"\n",
    "        symbol_object = f\"{symbol}-{chart_time}-{day}.zip\"\n",
    "        # Create the file path\n",
    "        file_path = Path(folder_path) / symbol_object\n",
    "        if not file_path.exists():\n",
    "            try:\n",
    "                # Download the file\n",
    "                urllib.request.urlretrieve(link, file_path)\n",
    "                count += 1\n",
    "            except:\n",
    "                #                     print(f'{link} not found')\n",
    "                continue\n",
    "    if count > 0:\n",
    "        print(f\"Daily Data Downloaded for {symbol},{chart_time}\")\n",
    "    else:\n",
    "        print(f\"you're already up to date for daily data for {symbol},{chart_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data_and_concatenate(\n",
    "        master_dictionary,\n",
    "        win_perc=master_dictionary[\"win_percentage\"],\n",
    "        loss_perc=master_dictionary[\"loss_percentage\"]):\n",
    "    # Set the start date and end date\n",
    "    start_date = datetime(2020, 1, 1)\n",
    "    end_date = datetime(2080, 1, 1)\n",
    "\n",
    "    # Initialize the list of year-month pairs\n",
    "    MONTH_ARRAY = []\n",
    "\n",
    "    # Iterate over the dates from start to end\n",
    "    date = start_date\n",
    "    while date < end_date:\n",
    "        # Format the date as a year-month pair\n",
    "        year_month = date.strftime(\"%Y-%m\")\n",
    "        #\n",
    "        # Add the year-month pair to the list\n",
    "        MONTH_ARRAY.append(year_month)\n",
    "\n",
    "        # Increment the date by one month\n",
    "        date += timedelta(days=31)\n",
    "    # Get the current date\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Format the date as a string in the desired format\n",
    "    date_string = now.strftime(\"%Y-%m\")\n",
    "\n",
    "    idx = MONTH_ARRAY.index(date_string)\n",
    "    MONTH_ARRAY = MONTH_ARRAY[:idx + 1]\n",
    "\n",
    "    # Get the current date\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Get the first day of the current month\n",
    "    first_day = now.replace(day=1)\n",
    "\n",
    "    # Create an empty list to store the days\n",
    "    DAY_ARRAY = []\n",
    "\n",
    "    # Loop through the days from the first day of the current month to today\n",
    "    while first_day <= now:\n",
    "        # Format the date as a string in the desired format\n",
    "        date_string = first_day.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Add the date string to the list\n",
    "        DAY_ARRAY.append(date_string)\n",
    "\n",
    "        # Move to the next day\n",
    "        first_day += timedelta(days=1)\n",
    "   \n",
    "\n",
    "    for symbol in master_dictionary[\"symbols\"]:\n",
    "        for chart_time in master_dictionary[\"chart_times\"]:\n",
    "            print(f\"setting up things for {symbol},{chart_time}\")\n",
    "\n",
    "            # Set up an empty list for the data frames\n",
    "            df_list = []\n",
    "\n",
    "            # Compile the regular expression pattern\n",
    "            pattern = re.compile(\n",
    "                f\"^{symbol}-{chart_time}-\\d{{4}}-\\d{{2}}\\.zip$\")\n",
    "\n",
    "            # Compile the regular expression pattern for daily zip files\n",
    "            pattern_daily = re.compile(\n",
    "                f\"^{symbol}-{chart_time}-\\d{{4}}-\\d{{2}}-\\d{{2}}\\.zip$\")\n",
    "\n",
    "            # Create the new folder path for daily ZIP files\n",
    "            new_daily_zip_folder_path = os.path.join(\n",
    "                download_dir, f\"{symbol}-{chart_time}-daily_data\")\n",
    "\n",
    "            # Create the new folder path for ZIP files\n",
    "            new_zip_folder_path = os.path.join(\n",
    "                download_dir, f\"{symbol}-{chart_time}-monthly_data\")\n",
    "\n",
    "            # Create the new folder path for CSV files\n",
    "            new_csv_folder_path = os.path.join(output_dir,\n",
    "                                               f\"{symbol}-{chart_time}\")\n",
    "\n",
    "            # Set the file name\n",
    "            concatenated_file_name = f\"{symbol}-{chart_time}_W{win_perc}_L{loss_perc}.csv\"\n",
    "\n",
    "            # Construct the file path\n",
    "            concatenated_file_path = os.path.join(new_csv_folder_path,\n",
    "                                                  concatenated_file_name)\n",
    "\n",
    "            if not Path(concatenated_file_path).exists():\n",
    "                print(\n",
    "                    f\"setting up things for the new symbol-chart_time combination : {symbol}{chart_time}\"\n",
    "                )\n",
    "                download_monthly_data(month_array=MONTH_ARRAY,\n",
    "                                      symbol=symbol,\n",
    "                                      chart_time=chart_time)\n",
    "                download_daily_data(day_array=DAY_ARRAY,\n",
    "                                    symbol=symbol,\n",
    "                                    chart_time=chart_time)\n",
    "\n",
    "                # Iterate over the files in the new zip folder\n",
    "                for file in os.listdir(new_zip_folder_path):\n",
    "                    # Check if the file matches the pattern\n",
    "                    if pattern.match(file):\n",
    "                        # Construct the file path\n",
    "                        file_path = os.path.join(new_zip_folder_path, file)\n",
    "\n",
    "                        # Extract the ZIP file\n",
    "                        with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                            zip_ref.extractall(new_csv_folder_path)\n",
    "\n",
    "                        # Construct the CSV file path\n",
    "                        csv_file_path = os.path.join(\n",
    "                            new_csv_folder_path,\n",
    "                            f\"{symbol}-{chart_time}{file[-12:-4]}.csv\")\n",
    "\n",
    "                        # Read the CSV file into a data frame, ignoring the headers\n",
    "                        df = pd.read_csv(csv_file_path, header=None)\n",
    "\n",
    "                        # Remove the first row (which contains the header)\n",
    "                        df = df.iloc[1:]\n",
    "\n",
    "                        # Add it to the list\n",
    "                        df_list.append(df)\n",
    "\n",
    "                # Iterate over the files in the new daily zip folder\n",
    "                for file in os.listdir(new_daily_zip_folder_path):\n",
    "                    # Check if the file matches the pattern\n",
    "                    if pattern_daily.match(file):\n",
    "                        # Construct the file path\n",
    "                        file_path = os.path.join(new_daily_zip_folder_path,\n",
    "                                                 file)\n",
    "\n",
    "                        # Extract the ZIP file\n",
    "                        with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                            zip_ref.extractall(new_csv_folder_path)\n",
    "                        # Construct the CSV file path\n",
    "                        csv_file_path = os.path.join(\n",
    "                            new_csv_folder_path,\n",
    "                            f\"{symbol}-{chart_time}-{file.split('-')[-3]}-{file.split('-')[-2]}-{file.split('-')[-1][:-4]}.csv\"\n",
    "                        )\n",
    "                        # Read the CSV file into a data frame, ignoring the headers\n",
    "                        df = pd.read_csv(csv_file_path, header=None)\n",
    "\n",
    "                        # Remove the first row (which contains the header)\n",
    "                        df = df.iloc[1:]\n",
    "\n",
    "                        # Add it to the list\n",
    "                        df_list.append(df)\n",
    "                # Concatenate the data frames in the list\n",
    "                df_final = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "                # Read the headers from the first CSV file\n",
    "                headers = pd.read_csv(csv_file_path, nrows=1).columns\n",
    "\n",
    "                # Set the headers as the column names of the final dataframe\n",
    "                df_final.columns = headers\n",
    "\n",
    "                # Convert 'open_time' and 'close_time' columns to datetime\n",
    "                df_final['open_time'] = pd.to_datetime(\n",
    "                    df_final['open_time'], unit='ms').dt.tz_localize(\n",
    "                        'UTC').dt.tz_convert('Asia/Kolkata')\n",
    "\n",
    "                # Delete the 'ignore' column\n",
    "                df_final = df_final.drop(['ignore', 'close_time'], axis=1)\n",
    "\n",
    "                # Add a new column called 'entry' that will take open of candle\n",
    "                df_final['entry'] = df_final['open']\n",
    "\n",
    "                # Write the data frame to the Excel file\n",
    "                df_final.to_csv(concatenated_file_path, index=False)\n",
    "\n",
    "                directory_final = Path(\n",
    "                    concatenated_file_path).parent  # Get the parent directory\n",
    "\n",
    "                # deleting all the other csvs\n",
    "                for file_path in directory_final.iterdir():\n",
    "                    if file_path != Path(concatenated_file_path):\n",
    "                        if file_path.is_file():\n",
    "                            file_path.unlink()\n",
    "                return f\"things set up for the new symbol-chart_time combination : {symbol}{chart_time}\"\n",
    "            else:\n",
    "                print(\n",
    "                    f\"setting up things only for incremental data for {symbol}{chart_time}\"\n",
    "                )\n",
    "                df_list = []\n",
    "                df = pd.read_csv(concatenated_file_path, header=None)\n",
    "                last_record = df.iloc[-1:]\n",
    "                df_list.append(last_record)\n",
    "\n",
    "                df = pd.read_csv(concatenated_file_path)\n",
    "                df['open_time'] = pd.to_datetime(df['open_time'])\n",
    "                last_record = df.iloc[-1:]\n",
    "\n",
    "                def calculate_reference_time(chart_time, base_time):\n",
    "                    # Extract the numeric value and unit from chart_time\n",
    "                    numeric_value = int(chart_time[:-1])\n",
    "                    unit = chart_time[-1]\n",
    "\n",
    "                    # Define a dictionary to map units to timedelta objects\n",
    "                    time_units = {\n",
    "                        'm': timedelta(minutes=numeric_value),\n",
    "                        'h': timedelta(hours=numeric_value),\n",
    "                    }\n",
    "\n",
    "                    # Calculate the reference time based on the unit and numeric value\n",
    "                    reference_time = base_time - time_units[unit]\n",
    "                    return reference_time.strftime('%H:%M:%S%z')\n",
    "\n",
    "                base_time = datetime.strptime(\"05:30:00+0530\", '%H:%M:%S%z')\n",
    "                reference_time = calculate_reference_time(\n",
    "                    chart_time, base_time)\n",
    "                print(reference_time)\n",
    "                # Check if the time part of 'open_time' is \"05:15:00+05:30\"\n",
    "                if last_record['open_time'].dt.strftime(\n",
    "                        '%H:%M:%S%z').item() == reference_time:\n",
    "                    # Calculate the last processed date by subtracting 1 day from the date part\n",
    "                    last_processed_date = (\n",
    "                        last_record['open_time'].dt.date -\n",
    "                        pd.DateOffset(days=1)).item().strftime('%Y-%m-%d')\n",
    "                    last_processed_date = datetime.strptime(\n",
    "                        last_processed_date, \"%Y-%m-%d\")\n",
    "                    print(last_processed_date)\n",
    "                    # Get today's date\n",
    "                    today = datetime.today()\n",
    "                    print(today)\n",
    "\n",
    "                    # Initialize DAY_ARRAY\n",
    "                    DAY_ARRAY = []\n",
    "                    # Start from the day after last_processed_date\n",
    "                    current_day = last_processed_date + timedelta(days=1)\n",
    "\n",
    "                    while current_day <= today:\n",
    "                        # Format the date as a string in the desired format\n",
    "                        date_string = current_day.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "                        # Add the date string to DAY_ARRAY\n",
    "                        DAY_ARRAY.append(date_string)\n",
    "\n",
    "                        # Move to the next day\n",
    "                        current_day += timedelta(days=1)\n",
    "\n",
    "                    download_daily_data(day_array=DAY_ARRAY,\n",
    "                                        symbol=symbol,\n",
    "                                        chart_time=chart_time)\n",
    "\n",
    "                    # Iterate over the files in the new daily zip folder\n",
    "                    for file in Path(new_daily_zip_folder_path).iterdir():\n",
    "                        # Check if the file matches the pattern\n",
    "                        if pattern_daily.match(file.name):\n",
    "                            # Extract the date part from the file name (e.g., \"2023-08-19\")\n",
    "                            zip_date = file.name.split('-')[-3:]\n",
    "                            zip_date_str = '-'.join(zip_date).replace(\n",
    "                                '.zip', '')\n",
    "\n",
    "                            # Check if the date is in DAY_ARRAY\n",
    "                            if zip_date_str in DAY_ARRAY:\n",
    "                                # Construct the file path\n",
    "                                file_path = file\n",
    "\n",
    "                                # Extract the ZIP file\n",
    "                                with zipfile.ZipFile(file_path,\n",
    "                                                     \"r\") as zip_ref:\n",
    "                                    zip_ref.extractall(new_csv_folder_path)\n",
    "\n",
    "                                # Construct the CSV file path\n",
    "                                csv_file_path = Path(\n",
    "                                    new_csv_folder_path\n",
    "                                ) / f\"{symbol}-{chart_time}-{zip_date_str}.csv\"\n",
    "\n",
    "                                # Read the CSV file into a data frame, ignoring the headers\n",
    "                                df = pd.read_csv(csv_file_path, header=None)\n",
    "\n",
    "                                # Remove the first row (which contains the header)\n",
    "                                df = df.iloc[1:]\n",
    "\n",
    "                                # Add it to the list\n",
    "                                df_list.append(df)\n",
    "                    for df in df_list[1:]:\n",
    "                        # Convert 'open_time' and 'close_time' columns to datetime\n",
    "                        df[0] = pd.to_datetime(\n",
    "                            df[0], unit='ms').dt.tz_localize(\n",
    "                                'UTC').dt.tz_convert('Asia/Kolkata')\n",
    "                        cols_to_drop = [6, 11]\n",
    "                        df.drop(df.columns[cols_to_drop], axis=1, inplace=True)\n",
    "    # Concatenate the data frames in the list\n",
    "                    if len(df_list) == 1:\n",
    "                        return \"no need to do anything, you're already having all the latest data\"\n",
    "                    else:\n",
    "                        df_final = pd.concat(df_list[1:], ignore_index=True)\n",
    "                        display(df_final.head())\n",
    "                        # Read the headers from the first CSV file\n",
    "                        headers = pd.read_csv(concatenated_file_path,\n",
    "                                              nrows=1).columns\n",
    "\n",
    "                        # Set the headers as the column names of the final dataframe\n",
    "                        df_final.columns = headers[0:len(headers) - 1]\n",
    "\n",
    "                        # Add a new column called 'entry' that will take open of candle\n",
    "                        df_final['entry'] = df_final['open']\n",
    "                        display(df_final.head())\n",
    "                        # Append the data frame to the existing CSV file in append mode without headers\n",
    "                        df_final.to_csv(concatenated_file_path,\n",
    "                                        mode='a',\n",
    "                                        header=False,\n",
    "                                        index=False)\n",
    "                        directory_final = Path(\n",
    "                            concatenated_file_path\n",
    "                        ).parent  # Get the parent directory\n",
    "\n",
    "                        # deleting all the other csvs\n",
    "                        for file_path in directory_final.iterdir():\n",
    "                            if file_path != Path(concatenated_file_path):\n",
    "                                if file_path.is_file():\n",
    "                                    file_path.unlink()\n",
    "                        return f\"things set up only for incremental data for {symbol}{chart_time}\"\n",
    "\n",
    "                else:\n",
    "                    return f\"Something is wrong with data. Last recorded time is not in sync with what is expected. Expected {reference_time} but got {last_record['open_time'].dt.strftime('%H:%M:%S%z').item()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wins_losses(master_dictionary, win_perc=0.73, loss_perc=0.4):\n",
    "    for symbol in master_dictionary[\"symbols\"]:\n",
    "        for chart_time in master_dictionary[\"chart_times\"]:\n",
    "            print(f\"calculating for {symbol}{chart_time}\")\n",
    "            # Construct the file name\n",
    "            file_name = f\"{symbol}-{chart_time}_W{win_perc}_L{loss_perc}.csv\"\n",
    "            file_path = Path(output_dir) / f\"{symbol}-{chart_time}/{file_name}\"\n",
    "            # Read the CSV file into a dataframe\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"if_short\"] = 0\n",
    "            df[\"if_long\"] = 0\n",
    "            df[\"long_target\"] = np.nan\n",
    "            df[\"short_target\"] = np.nan\n",
    "            df[\"long_stop_loss\"] = np.nan\n",
    "            df[\"short_stop_loss\"] = np.nan\n",
    "            df[\"shorts_win_after\"] = np.nan\n",
    "            df[\"longs_win_after\"] = np.nan\n",
    "            df[\"dual_loss\"] = 0\n",
    "            df[\"entered_before\"] = np.nan\n",
    "\n",
    "            for i in range(len(df)):\n",
    "                if df[\"entry\"][i]:\n",
    "                    long_target = df[\"entry\"][i] * (1 + win_perc / 100)\n",
    "                    short_target = df[\"entry\"][i] * (1 - win_perc / 100)\n",
    "                    long_stop_loss = df[\"entry\"][i] * (1 - loss_perc / 100)\n",
    "                    short_stop_loss = df[\"entry\"][i] * (1 + loss_perc / 100)\n",
    "                    df.loc[i, 'long_target'] = long_target\n",
    "                    df.loc[i, 'long_stop_loss'] = long_stop_loss\n",
    "                    for j in range(i, len(df)):\n",
    "                        if df[\"high\"][j] >= long_target:\n",
    "                            if df[\"low\"][j] <= long_stop_loss:\n",
    "                                df.loc[i, 'if_long'] = -1\n",
    "                                df.loc[i, 'dual_loss'] = 1\n",
    "                                df.loc[i, 'entered_before'] = j - i\n",
    "                            else:\n",
    "                                df.loc[i, 'if_long'] = 1\n",
    "                                df.loc[i, 'longs_win_after'] = j - i\n",
    "                            break\n",
    "                        elif df[\"low\"][j] <= long_stop_loss:\n",
    "                            df.loc[i, 'if_long'] = -1\n",
    "                            break\n",
    "                    df.loc[i, 'short_target'] = short_target\n",
    "                    df.loc[i, 'short_stop_loss'] = short_stop_loss\n",
    "                    for j in range(i, len(df)):\n",
    "                        if df[\"low\"][j] <= short_target:\n",
    "                            if df[\"high\"][j] >= short_stop_loss:\n",
    "                                df.loc[i, 'if_short'] = -1\n",
    "                                df.loc[i, 'dual_loss'] = 1\n",
    "                                df.loc[i, 'entered_before'] = j - i\n",
    "                            else:\n",
    "                                df.loc[i, 'if_short'] = 1\n",
    "                                df.loc[i, 'shorts_win_after'] = j - i\n",
    "                            break\n",
    "                        elif df[\"high\"][j] >= short_stop_loss:\n",
    "                            df.loc[i, 'if_short'] = -1\n",
    "                            break\n",
    "            # Save the updated dataframe to the CSV file\n",
    "            df.to_csv(file_path, index=False)\n",
    "\n",
    "    return (\"calculated wins and losses \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_indicator_values_new(master_dictionary, monthly_or_daily_1_2, win_perc, loss_perc):\n",
    "    # Iterate over the symbols and chart times\n",
    "    for symbol in master_dictionary[\"symbols\"]:\n",
    "        for chart_time in master_dictionary[\"chart_times\"]:\n",
    "            # Construct the file name\n",
    "            file_name = f\"{symbol}-{chart_time}_W{win_perc}_L{loss_perc}.csv\"\n",
    "            file_path = Path(output_dir) / f\"{symbol}-{chart_time}/{file_name}\"\n",
    "\n",
    "            # Read the CSV file into a dataframe\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(df.dtypes)\n",
    "            #########Overlap Studies\n",
    "            new_columns = pd.DataFrame()\n",
    "            new_columns['HT_TRENDLINE'] = talib.HT_TRENDLINE(df['close'])\n",
    "            #         df['MAMA'], df['FAMA'] = talib.MAMA(df['close'], fastlimit=0, slowlimit=0)\n",
    "            #         df['MAVP'] = talib.MAVP(df['close'], periods=None, minperiod=2, maxperiod=30, matype=0)\n",
    "            new_columns['SAR'] = talib.SAR(df['high'], df['low'], acceleration=0, maximum=0)\n",
    "            new_columns['SAREXT'] = talib.SAREXT(df['high'], df['low'])\n",
    "            new_columns['T3'] = talib.T3(df['close'], timeperiod=5, vfactor=0)\n",
    "#             #########Momentum Indicators\n",
    "            new_columns['APO'] = talib.APO(df['close'], fastperiod=12, slowperiod=26)\n",
    "            new_columns['BOP'] = talib.BOP(df['open'], df['high'], df['low'], df['close'])\n",
    "            macd, macd_signal, macd_hist = talib.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            new_columns['MACD'] = macd\n",
    "            new_columns['MACD_signal'] = macd_signal\n",
    "            new_columns['MACD_hist'] = macd_hist\n",
    "            new_columns['PPO'] = talib.PPO(df['close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "            new_columns['TRIX'] = talib.TRIX(df['close'])\n",
    "            new_columns['ULTOSC'] = talib.ULTOSC(df['high'], df['low'], df['close'])\n",
    "            new_columns['WILLR'] = talib.WILLR(df['high'], df['low'], df['close'])\n",
    "\n",
    "            \n",
    "\n",
    "            # Not Working ATM\n",
    "            #         new_columns['STOCH'] = talib.STOCH(df['high'], df['low'], df['close'])\n",
    "            #         new_columns['STOCHF'] = talib.STOCHF(df['high'], df['low'], df['close'])\n",
    "            #         new_columns['STOCHRSI'] = talib.STOCHRSI(df['close'])\n",
    "            #         new_columns['MACDEXT'] = talib.MACDEXT(df['close'], fastperiod=12, fastmatype=0, slowperiod=26, slowmatype=0, signalperiod=9, signalmatype=0)\n",
    "            #         new_columns['MACDFIX'] = talib.MACDFIX(df['close'], signalperiod=9)\n",
    "            #########Volume Indicators\n",
    "            new_columns['AD'] = talib.AD(df['high'], df['low'], df['close'], df['volume'])\n",
    "            new_columns['ADOSC'] = talib.ADOSC(df['high'], df['low'], df['close'], df['volume'], fastperiod=3, slowperiod=10)\n",
    "            new_columns['OBV'] = talib.OBV(df['close'], df['volume'])\n",
    "\n",
    "            #########Cycle Indicators\n",
    "            new_columns['HT_DCPERIOD'] = talib.HT_DCPERIOD(df['close'])\n",
    "            new_columns['HT_DCPHASE'] = talib.HT_DCPHASE(df['close'])\n",
    "            new_columns['HT_PHASOR_inphase'], new_columns['HT_PHASOR_quadrature'] = talib.HT_PHASOR(df['close'])\n",
    "            # new_columns['HT_SINE'] = talib.HT_SINE(df['close'])\n",
    "            new_columns['HT_TRENDMODE'] = talib.HT_TRENDMODE(df['close'])\n",
    "\n",
    "            #########Price Transform\n",
    "            new_columns['AVGPRICE'] = talib.AVGPRICE(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['MEDPRICE'] = talib.MEDPRICE(df['high'], df['low'])\n",
    "            new_columns['TYPPRICE'] = talib.TYPPRICE(df['high'], df['low'], df['close'])\n",
    "            new_columns['WCLPRICE'] = talib.WCLPRICE(df['high'], df['low'], df['close'])\n",
    "            #########Volatility Indicators\n",
    "            new_columns['TRANGE'] = talib.TRANGE(df['high'], df['low'], df['close'])\n",
    "            #########Pattern Recognition\n",
    "            new_columns['CDL2CROWS'] = talib.CDL2CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDL3BLACKCROWS'] = talib.CDL3BLACKCROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDL3INSIDE'] = talib.CDL3INSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDL3LINESTRIKE'] = talib.CDL3LINESTRIKE(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDL3OUTSIDE'] = talib.CDL3OUTSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDL3STARSINSOUTH'] = talib.CDL3STARSINSOUTH(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDL3WHITESOLDIERS'] = talib.CDL3WHITESOLDIERS(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLABANDONEDBABY'] = talib.CDLABANDONEDBABY(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "\n",
    "            new_columns['CDLADVANCEBLOCK'] = talib.CDLADVANCEBLOCK(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLBELTHOLD'] = talib.CDLBELTHOLD(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLBREAKAWAY'] = talib.CDLBREAKAWAY(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLCLOSINGMARUBOZU'] = talib.CDLCLOSINGMARUBOZU(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLCONCEALBABYSWALL'] = talib.CDLCONCEALBABYSWALL(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLCOUNTERATTACK'] = talib.CDLCOUNTERATTACK(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLDARKCLOUDCOVER'] = talib.CDLDARKCLOUDCOVER(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "\n",
    "            new_columns['CDLDOJI'] = talib.CDLDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLDOJISTAR'] = talib.CDLDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLDRAGONFLYDOJI'] = talib.CDLDRAGONFLYDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLENGULFING'] = talib.CDLENGULFING(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLEVENINGDOJISTAR'] = talib.CDLEVENINGDOJISTAR(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "\n",
    "            new_columns['CDLEVENINGSTAR'] = talib.CDLEVENINGSTAR(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            new_columns['CDLGAPSIDESIDEWHITE'] = talib.CDLGAPSIDESIDEWHITE(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLGRAVESTONEDOJI'] = talib.CDLGRAVESTONEDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLHAMMER'] = talib.CDLHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLHANGINGMAN'] = talib.CDLHANGINGMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLHARAMI'] = talib.CDLHARAMI(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLHARAMICROSS'] = talib.CDLHARAMICROSS(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLHIGHWAVE'] = talib.CDLHIGHWAVE(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLHIKKAKE'] = talib.CDLHIKKAKE(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLHIKKAKEMOD'] = talib.CDLHIKKAKEMOD(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLHOMINGPIGEON'] = talib.CDLHOMINGPIGEON(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLIDENTICAL3CROWS'] = talib.CDLIDENTICAL3CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLINNECK'] = talib.CDLINNECK(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLINVERTEDHAMMER'] = talib.CDLINVERTEDHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLKICKING'] = talib.CDLKICKING(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLKICKINGBYLENGTH'] = talib.CDLKICKINGBYLENGTH(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLLADDERBOTTOM'] = talib.CDLLADDERBOTTOM(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLLONGLEGGEDDOJI'] = talib.CDLLONGLEGGEDDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLLONGLINE'] = talib.CDLLONGLINE(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLMARUBOZU'] = talib.CDLMARUBOZU(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLMATCHINGLOW'] = talib.CDLMATCHINGLOW(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLMATHOLD'] = talib.CDLMATHOLD(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            new_columns['CDLMORNINGDOJISTAR'] = talib.CDLMORNINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLMORNINGSTAR'] = talib.CDLMORNINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLONNECK'] = talib.CDLONNECK(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLPIERCING'] = talib.CDLPIERCING(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLRICKSHAWMAN'] = talib.CDLRICKSHAWMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLRISEFALL3METHODS'] = talib.CDLRISEFALL3METHODS(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLSEPARATINGLINES'] = talib.CDLSEPARATINGLINES(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLSHOOTINGSTAR'] = talib.CDLSHOOTINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLSHORTLINE'] = talib.CDLSHORTLINE(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLSPINNINGTOP'] = talib.CDLSPINNINGTOP(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLSTALLEDPATTERN'] = talib.CDLSTALLEDPATTERN(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLSTICKSANDWICH'] = talib.CDLSTICKSANDWICH(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLTAKURI'] = talib.CDLTAKURI(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLTASUKIGAP'] = talib.CDLTASUKIGAP(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLTHRUSTING'] = talib.CDLTHRUSTING(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLTRISTAR'] = talib.CDLTRISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLUNIQUE3RIVER'] = talib.CDLUNIQUE3RIVER(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLUPSIDEGAP2CROWS'] = talib.CDLUPSIDEGAP2CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            new_columns['CDLXSIDEGAP3METHODS'] = talib.CDLXSIDEGAP3METHODS(df['open'], df['high'], df['low'], df['close'])\n",
    "            #########Statistic Functions\n",
    "            new_columns['LINEARREG'] = talib.LINEARREG(df['close'])\n",
    "            new_columns['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(df['close'])\n",
    "            new_columns['LINEARREG_INTERCEPT'] = talib.LINEARREG_INTERCEPT(df['close'])\n",
    "            new_columns['LINEARREG_SLOPE'] = talib.LINEARREG_SLOPE(df['close'])\n",
    "            #         new_columns['STDDEV'] = df['close'].rolling(timeperiod).std()\n",
    "            new_columns['TSF'] = talib.TSF(df['close'])\n",
    "            new_columns['VAR'] = talib.VAR(df['close'])\n",
    "            # Iterate over the time periods\n",
    "            for timeperiod in master_dictionary[\"timeperiods\"]:\n",
    "                #########Overlap Studies\n",
    "                new_columns[f'BB_upper_{timeperiod}'], new_columns[f'BB_middle_{timeperiod}'], new_columns[\n",
    "                    f'BB_lower_{timeperiod}'] = talib.BBANDS(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'DEMA_{timeperiod}'] = talib.DEMA(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'EMA_{timeperiod}'] = talib.EMA(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'KAMA_{timeperiod}'] = talib.KAMA(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'MA_{timeperiod}'] = talib.MA(df['close'], timeperiod=timeperiod)\n",
    "                #         new_columns['MAMA'], new_columns['FAMA'] = talib.MAMA(df['close'], fastlimit=0, slowlimit=0)\n",
    "                #         new_columns['MAVP'] = talib.MAVP(df['close'], periods=None, minperiod=2, maxperiod=30, matype=0)\n",
    "                new_columns[f'MIDPOINT_{timeperiod}'] = talib.MIDPOINT(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'MIDPRICE_{timeperiod}'] = talib.MIDPRICE(df['high'], df['low'], timeperiod=timeperiod)\n",
    "                new_columns[f'SMA_{timeperiod}'] = talib.SMA(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'TEMA_{timeperiod}'] = talib.TEMA(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'TRIMA_{timeperiod}'] = talib.TRIMA(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'WMA_{timeperiod}'] = talib.WMA(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'ADX_{timeperiod}'] = talib.ADX(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'ADXR_{timeperiod}'] = talib.ADXR(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'AROON_up_{timeperiod}'], new_columns[f'AROON_down_{timeperiod}'] = talib.AROON(df['high'], df['low'],\n",
    "                                                                                           timeperiod=timeperiod)\n",
    "                new_columns[f'AROONOSC_{timeperiod}'] = talib.AROONOSC(df['high'], df['low'], timeperiod=timeperiod)\n",
    "                new_columns[f'CCI_{timeperiod}'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'CMO_{timeperiod}'] = talib.CMO(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'DX_{timeperiod}'] = talib.DX(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'MFI_{timeperiod}'] = talib.MFI(df['high'], df['low'], df['close'], df['volume'],\n",
    "                                                    timeperiod=timeperiod)\n",
    "                new_columns[f'MINUS_DI_{timeperiod}'] = talib.MINUS_DI(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'MINUS_DM_{timeperiod}'] = talib.MINUS_DM(df['high'], df['low'], timeperiod=timeperiod)\n",
    "                new_columns[f'MOM_{timeperiod}'] = talib.MOM(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'PLUS_DI_{timeperiod}'] = talib.PLUS_DI(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'PLUS_DM_{timeperiod}'] = talib.PLUS_DM(df['high'], df['low'], timeperiod=timeperiod)\n",
    "                new_columns[f'ROC_{timeperiod}'] = talib.ROC(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'ROCP_{timeperiod}'] = talib.ROCP(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'ROCR_{timeperiod}'] = talib.ROCR(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'ROCR100_{timeperiod}'] = talib.ROCR100(df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'RSI_{timeperiod}'] = talib.RSI(df['close'], timeperiod=timeperiod)\n",
    "\n",
    "                new_columns[f'ATR_{timeperiod}'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                new_columns[f'NATR_{timeperiod}'] = talib.NATR(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                #########Statistic Functions\n",
    "                new_columns[f'BETA_{timeperiod}'] = talib.BETA(df['high'], df['low'], timeperiod=timeperiod)\n",
    "                new_columns[f'CORREL_{timeperiod}'] = talib.CORREL(df['high'], df['low'], timeperiod=timeperiod)\n",
    "            # Save the updated dataframe to the CSV file\n",
    "            df = pd.concat([df, new_columns], axis=1)\n",
    "            df.to_csv(file_path, index=False)\n",
    "    return (\"indicators are added to the csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_indicator_values_old(master_dictionary, monthly_or_daily_1_2):\n",
    "#     # Iterate over the symbols and chart times\n",
    "#     for symbol in master_dictionary[\"symbols\"]:\n",
    "#         for chart_time in master_dictionary[\"chart_times\"]:\n",
    "#             # Construct the file name\n",
    "#             file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "#             if monthly_or_daily_1_2 in [\"m\", \"M\", \"monthly\", 1]:\n",
    "#                 # Construct the file path\n",
    "#                 file_path = Path(output_dir) / f\"{symbol}-{chart_time}-monthly_data/{file_name}\"\n",
    "#             elif monthly_or_daily_1_2 in [\"d\", \"D\", \"daily\", 2]:\n",
    "#                 # Construct the file path\n",
    "#                 file_path = Path(output_dir) / f\"{symbol}-{chart_time}-daily_data/{file_name}\"\n",
    "#             # Read the CSV file into a dataframe\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             print(df.dtypes)\n",
    "#             #########Overlap Studies\n",
    "#             df['BB_upper'], df['BB_middle'], df['BB_lower'] = talib.BBANDS(df['close'], timeperiod=5)\n",
    "#             df['DEMA'] = talib.DEMA(df['close'], timeperiod=30)\n",
    "#             df['EMA-50'] = talib.EMA(df['close'], timeperiod=50)\n",
    "#             df['EMA-200'] = talib.EMA(df['close'], timeperiod=200)\n",
    "#             df['HT_TRENDLINE'] = talib.HT_TRENDLINE(df['close'])\n",
    "#             df['KAMA'] = talib.KAMA(df['close'], timeperiod=30)\n",
    "#             df['MA'] = talib.MA(df['close'], timeperiod=14)\n",
    "#             #         df['MAMA'], df['FAMA'] = talib.MAMA(df['close'], fastlimit=0, slowlimit=0)\n",
    "#             #         df['MAVP'] = talib.MAVP(df['close'], periods=None, minperiod=2, maxperiod=30, matype=0)\n",
    "#             df['MIDPOINT'] = talib.MIDPOINT(df['close'], timeperiod=14)\n",
    "#             df['MIDPRICE'] = talib.MIDPRICE(df['high'], df['low'], timeperiod=14)\n",
    "#             df['SAR'] = talib.SAR(df['high'], df['low'], acceleration=0, maximum=0)\n",
    "#             df['SAREXT'] = talib.SAREXT(df['high'], df['low'])\n",
    "#             df['SMA'] = talib.SMA(df['close'], timeperiod=14)\n",
    "#             df['T3'] = talib.T3(df['close'], timeperiod=5, vfactor=0)\n",
    "#             df['TEMA'] = talib.TEMA(df['close'])\n",
    "#             df['TRIMA'] = talib.TRIMA(df['close'])\n",
    "#             df['WMA'] = talib.WMA(df['close'])\n",
    "#             #########Momentum Indicators\n",
    "#             df['ADX'] = talib.ADX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "#             df['ADXR'] = talib.ADXR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "#             df['APO'] = talib.APO(df['close'], fastperiod=12, slowperiod=26)\n",
    "#             df['AROON_up'], df['AROON_down'] = talib.AROON(df['high'], df['low'], timeperiod=14)\n",
    "#             df['AROONOSC'] = talib.AROONOSC(df['high'], df['low'], timeperiod=14)\n",
    "#             df['BOP'] = talib.BOP(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CCI'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "#             df['CMO'] = talib.CMO(df['close'], timeperiod=14)\n",
    "#             df['DX'] = talib.DX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "#             df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(df['close'], fastperiod=12, slowperiod=26,\n",
    "#                                                                         signalperiod=9)\n",
    "#             df['MFI'] = talib.MFI(df['high'], df['low'], df['close'], df['volume'], timeperiod=14)\n",
    "#             df['MINUS_DI'] = talib.MINUS_DI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "#             df['MINUS_DM'] = talib.MINUS_DM(df['high'], df['low'], timeperiod=14)\n",
    "#             df['MOM'] = talib.MOM(df['close'], timeperiod=14)\n",
    "#             df['PLUS_DI'] = talib.PLUS_DI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "#             df['PLUS_DM'] = talib.PLUS_DM(df['high'], df['low'], timeperiod=14)\n",
    "#             df['PPO'] = talib.PPO(df['close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "#             df['ROC'] = talib.ROC(df['close'], timeperiod=14)\n",
    "#             df['ROCP'] = talib.ROCP(df['close'], timeperiod=14)\n",
    "#             df['ROCR'] = talib.ROCR(df['close'], timeperiod=14)\n",
    "#             df['ROCR100'] = talib.ROCR100(df['close'], timeperiod=14)\n",
    "#             df['RSI'] = talib.RSI(df['close'], timeperiod=8)\n",
    "#             df['TRIX'] = talib.TRIX(df['close'])\n",
    "#             df['ULTOSC'] = talib.ULTOSC(df['high'], df['low'], df['close'])\n",
    "#             df['WILLR'] = talib.WILLR(df['high'], df['low'], df['close'])\n",
    "\n",
    "#             # Not Working ATM\n",
    "#             #         df['STOCH'] = talib.STOCH(df['high'], df['low'], df['close'])\n",
    "#             #         df['STOCHF'] = talib.STOCHF(df['high'], df['low'], df['close'])\n",
    "#             #         df['STOCHRSI'] = talib.STOCHRSI(df['close'])\n",
    "#             #         df['MACDEXT'] = talib.MACDEXT(df['close'], fastperiod=12, fastmatype=0, slowperiod=26, slowmatype=0, signalperiod=9, signalmatype=0)\n",
    "#             #         df['MACDFIX'] = talib.MACDFIX(df['close'], signalperiod=9)\n",
    "#             #########Volume Indicators\n",
    "#             df['AD'] = talib.AD(df['high'], df['low'], df['close'], df['volume'])\n",
    "#             df['ADOSC'] = talib.ADOSC(df['high'], df['low'], df['close'], df['volume'], fastperiod=3, slowperiod=10)\n",
    "#             df['OBV'] = talib.OBV(df['close'], df['volume'])\n",
    "#             #########Cycle Indicators\n",
    "#             df['HT_DCPERIOD'] = talib.HT_DCPERIOD(df['close'])\n",
    "#             df['HT_DCPHASE'] = talib.HT_DCPHASE(df['close'])\n",
    "#             df['HT_PHASOR_inphase'], df['HT_PHASOR_quadrature'] = talib.HT_PHASOR(df['close'])\n",
    "#             #         df['HT_SINE'] = talib.HT_SINE(df['close'])\n",
    "#             df['HT_TRENDMODE'] = talib.HT_TRENDMODE(df['close'])\n",
    "#             #########Price Transform\n",
    "#             df['AVGPRICE'] = talib.AVGPRICE(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['MEDPRICE'] = talib.MEDPRICE(df['high'], df['low'])\n",
    "#             df['TYPPRICE'] = talib.TYPPRICE(df['high'], df['low'], df['close'])\n",
    "#             df['WCLPRICE'] = talib.WCLPRICE(df['high'], df['low'], df['close'])\n",
    "#             #########Volatility Indicators\n",
    "#             df['ATR'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "#             df['NATR'] = talib.NATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "#             df['TRANGE'] = talib.TRANGE(df['high'], df['low'], df['close'])\n",
    "#             #########Pattern Recognition\n",
    "#             df['CDL2CROWS'] = talib.CDL2CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDL3BLACKCROWS'] = talib.CDL3BLACKCROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDL3INSIDE'] = talib.CDL3INSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDL3LINESTRIKE'] = talib.CDL3LINESTRIKE(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDL3OUTSIDE'] = talib.CDL3OUTSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDL3STARSINSOUTH'] = talib.CDL3STARSINSOUTH(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDL3WHITESOLDIERS'] = talib.CDL3WHITESOLDIERS(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLABANDONEDBABY'] = talib.CDLABANDONEDBABY(df['open'], df['high'], df['low'], df['close'],\n",
    "#                                                             penetration=0)\n",
    "#             df['CDLADVANCEBLOCK'] = talib.CDLADVANCEBLOCK(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLBELTHOLD'] = talib.CDLBELTHOLD(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLBREAKAWAY'] = talib.CDLBREAKAWAY(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLCLOSINGMARUBOZU'] = talib.CDLCLOSINGMARUBOZU(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLCONCEALBABYSWALL'] = talib.CDLCONCEALBABYSWALL(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLCOUNTERATTACK'] = talib.CDLCOUNTERATTACK(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLDARKCLOUDCOVER'] = talib.CDLDARKCLOUDCOVER(df['open'], df['high'], df['low'], df['close'],\n",
    "#                                                               penetration=0)\n",
    "#             df['CDLDOJI'] = talib.CDLDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLDOJISTAR'] = talib.CDLDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLDRAGONFLYDOJI'] = talib.CDLDRAGONFLYDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLENGULFING'] = talib.CDLENGULFING(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLEVENINGDOJISTAR'] = talib.CDLEVENINGDOJISTAR(df['open'], df['high'], df['low'], df['close'],\n",
    "#                                                                 penetration=0)\n",
    "#             df['CDLEVENINGSTAR'] = talib.CDLEVENINGSTAR(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "#             df['CDLGAPSIDESIDEWHITE'] = talib.CDLGAPSIDESIDEWHITE(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLGRAVESTONEDOJI'] = talib.CDLGRAVESTONEDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLHAMMER'] = talib.CDLHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLHANGINGMAN'] = talib.CDLHANGINGMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLHARAMI'] = talib.CDLHARAMI(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLHARAMICROSS'] = talib.CDLHARAMICROSS(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLHIGHWAVE'] = talib.CDLHIGHWAVE(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLHIKKAKE'] = talib.CDLHIKKAKE(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLHIKKAKEMOD'] = talib.CDLHIKKAKEMOD(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLHOMINGPIGEON'] = talib.CDLHOMINGPIGEON(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLIDENTICAL3CROWS'] = talib.CDLIDENTICAL3CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLINNECK'] = talib.CDLINNECK(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLINVERTEDHAMMER'] = talib.CDLINVERTEDHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLKICKING'] = talib.CDLKICKING(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLKICKINGBYLENGTH'] = talib.CDLKICKINGBYLENGTH(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLLADDERBOTTOM'] = talib.CDLLADDERBOTTOM(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLLONGLEGGEDDOJI'] = talib.CDLLONGLEGGEDDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLLONGLINE'] = talib.CDLLONGLINE(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLMARUBOZU'] = talib.CDLMARUBOZU(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLMATCHINGLOW'] = talib.CDLMATCHINGLOW(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLMATHOLD'] = talib.CDLMATHOLD(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "#             df['CDLMORNINGDOJISTAR'] = talib.CDLMORNINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLMORNINGSTAR'] = talib.CDLMORNINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLONNECK'] = talib.CDLONNECK(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLPIERCING'] = talib.CDLPIERCING(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLRICKSHAWMAN'] = talib.CDLRICKSHAWMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLRISEFALL3METHODS'] = talib.CDLRISEFALL3METHODS(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLSEPARATINGLINES'] = talib.CDLSEPARATINGLINES(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLSHOOTINGSTAR'] = talib.CDLSHOOTINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLSHORTLINE'] = talib.CDLSHORTLINE(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLSPINNINGTOP'] = talib.CDLSPINNINGTOP(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLSTALLEDPATTERN'] = talib.CDLSTALLEDPATTERN(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLSTICKSANDWICH'] = talib.CDLSTICKSANDWICH(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLTAKURI'] = talib.CDLTAKURI(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLTASUKIGAP'] = talib.CDLTASUKIGAP(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLTHRUSTING'] = talib.CDLTHRUSTING(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLTRISTAR'] = talib.CDLTRISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLUNIQUE3RIVER'] = talib.CDLUNIQUE3RIVER(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLUPSIDEGAP2CROWS'] = talib.CDLUPSIDEGAP2CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "#             df['CDLXSIDEGAP3METHODS'] = talib.CDLXSIDEGAP3METHODS(df['open'], df['high'], df['low'], df['close'])\n",
    "#             #########Statistic Functions\n",
    "#             df['BETA'] = talib.BETA(df['high'], df['low'], timeperiod=5)\n",
    "#             df['CORREL'] = talib.CORREL(df['high'], df['low'], timeperiod=30)\n",
    "#             df['LINEARREG'] = talib.LINEARREG(df['close'])\n",
    "#             df['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(df['close'])\n",
    "#             df['LINEARREG_INTERCEPT'] = talib.LINEARREG_INTERCEPT(df['close'])\n",
    "#             df['LINEARREG_SLOPE'] = talib.LINEARREG_SLOPE(df['close'])\n",
    "#             #         df['STDDEV'] = df['close'].rolling(timeperiod).std()\n",
    "#             df['TSF'] = talib.TSF(df['close'])\n",
    "#             df['VAR'] = talib.VAR(df['close'])\n",
    "\n",
    "#             # Save the updated dataframe to the CSV file\n",
    "#             df.to_csv(file_path, index=False)\n",
    "#     return (\"indicators are added to the csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data creation utilities successfully initialized\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
