{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad10b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO since dual logic implementation with optimization is a pain, and we are already marking such candles as loss, might as well skip it for now and come back to it later.\n",
    "# def calculate_wins_losses_optimized_with_dual_logic(master_dictionary, win_perc=0.73, loss_perc=0.4):\n",
    "#     for symbol in master_dictionary[\"symbols\"]:\n",
    "#         for chart_time in master_dictionary[\"chart_times\"]:\n",
    "#             try:\n",
    "#                 print(f\"Calculating for {symbol} {chart_time}\")\n",
    "\n",
    "#                 # Define the directory for processed data\n",
    "#                 processed_data_dir = Path(output_dir) / f\"{symbol}-{chart_time}/processed_data\"\n",
    "\n",
    "#                 # Create the directory if it doesn't exist\n",
    "#                 processed_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#                 # Construct the file names\n",
    "#                 og_file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "#                 og_file_path = Path(output_dir) / f\"{symbol}-{chart_time}/{og_file_name}\"\n",
    "#                 new_file_name = f\"{symbol}-{chart_time}_W{win_perc}_L{loss_perc}.csv\"\n",
    "#                 new_file_path = processed_data_dir / new_file_name\n",
    "\n",
    "#                 # Read the CSV file into a dataframe\n",
    "#                 df = pd.read_csv(og_file_path)\n",
    "\n",
    "#                 # Initialize new columns\n",
    "#                 df[\"if_short\"] = np.nan\n",
    "#                 df[\"if_long\"] = np.nan\n",
    "#                 df[\"long_target\"] = df[\"entry\"] * (1 + win_perc / 100)\n",
    "#                 df[\"short_target\"] = df[\"entry\"] * (1 - win_perc / 100)\n",
    "#                 df[\"long_stop_loss\"] = df[\"entry\"] * (1 - loss_perc / 100)\n",
    "#                 df[\"short_stop_loss\"] = df[\"entry\"] * (1 + loss_perc / 100)\n",
    "#                 df[\"shorts_win_after\"] = np.nan\n",
    "#                 df[\"longs_win_after\"] = np.nan\n",
    "#                 df[\"shorts_lose_after\"] = np.nan\n",
    "#                 df[\"longs_lose_after\"] = np.nan\n",
    "#                 df[\"dual_loss\"] = 0\n",
    "#                 df[\"entered_before\"] = np.nan\n",
    "\n",
    "#                 # Define functions to compute win/loss results\n",
    "#                 def compute_win_loss(row):\n",
    "#                     entry_idx = row.name\n",
    "#                     long_target_reached = df.loc[entry_idx:, 'high'].ge(row['long_target']).idxmax() if df.loc[entry_idx:, 'high'].ge(row['long_target']).any() else np.nan\n",
    "#                     long_stop_loss_reached = df.loc[entry_idx:, 'low'].le(row['long_stop_loss']).idxmax() if df.loc[entry_idx:, 'low'].le(row['long_stop_loss']).any() else np.nan\n",
    "#                     short_target_reached = df.loc[entry_idx:, 'low'].le(row['short_target']).idxmax() if df.loc[entry_idx:, 'low'].le(row['short_target']).any() else np.nan\n",
    "#                     short_stop_loss_reached = df.loc[entry_idx:, 'high'].ge(row['short_stop_loss']).idxmax() if df.loc[entry_idx:, 'high'].ge(row['short_stop_loss']).any() else np.nan\n",
    "\n",
    "#                     if long_target_reached is not np.nan and (long_stop_loss_reached is np.nan or long_target_reached < long_stop_loss_reached):\n",
    "#                         df.at[entry_idx, 'if_long'] = 1\n",
    "#                         df.at[entry_idx, 'longs_win_after'] = long_target_reached - entry_idx\n",
    "#                     elif long_stop_loss_reached is not np.nan:\n",
    "#                         df.at[entry_idx, 'if_long'] = -1\n",
    "# #                         df.at[entry_idx, 'longs_lose_after'] = long_stop_loss_reached - entry_idx\n",
    "# #                         df.at[entry_idx, 'dual_loss'] = 1\n",
    "# #                         df.at[entry_idx, 'entered_before'] = long_stop_loss_reached - entry_idx\n",
    "\n",
    "#                     if short_target_reached is not np.nan and (short_stop_loss_reached is np.nan or short_target_reached < short_stop_loss_reached):\n",
    "#                         df.at[entry_idx, 'if_short'] = 1\n",
    "#                         df.at[entry_idx, 'shorts_win_after'] = short_target_reached - entry_idx\n",
    "#                     elif short_stop_loss_reached is not np.nan:\n",
    "#                         df.at[entry_idx, 'if_short'] = -1\n",
    "# #                         df.at[entry_idx, 'shorts_lose_after'] = short_stop_loss_reached - entry_idx\n",
    "# #                         df.at[entry_idx, 'dual_loss'] = 1\n",
    "# #                         df.at[entry_idx, 'entered_before'] = short_stop_loss_reached - entry_idx\n",
    "\n",
    "#                 # Apply the function to each row\n",
    "#                 tqdm.pandas(desc=f\"Processing {symbol}-{chart_time}\")\n",
    "#                 df.apply(compute_win_loss, axis=1)\n",
    "\n",
    "#                 # Save the processed data\n",
    "#                 df.to_csv(new_file_path, index=False)\n",
    "#                 print(f\"Processed file saved as {new_file_name}\")\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {symbol} {chart_time}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wins_losses_old(master_dictionary, win_perc=0.73, loss_perc=0.4):\n",
    "    for symbol in master_dictionary[\"symbols\"]:\n",
    "        for chart_time in master_dictionary[\"chart_times\"]:\n",
    "            try:\n",
    "                print(f\"Calculating for {symbol} {chart_time}\")\n",
    "\n",
    "                # Define the directory for processed data\n",
    "                processed_data_dir = Path(output_dir) / f\"{symbol}-{chart_time}/processed_data\"\n",
    "\n",
    "                # Create the directory if it doesn't exist\n",
    "                if not processed_data_dir.exists():\n",
    "                    processed_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Construct the file name\n",
    "                og_file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "                og_file_path = Path(output_dir) / f\"{symbol}-{chart_time}/{og_file_name}\"\n",
    "                new_file_name = f\"{symbol}-{chart_time}_W{win_perc}_L{loss_perc}.csv\"\n",
    "                new_file_path = processed_data_dir / new_file_name\n",
    "\n",
    "                # Read the CSV file into a dataframe\n",
    "                df = pd.read_csv(og_file_path)\n",
    "\n",
    "                # Initialize new columns\n",
    "                df[\"if_short\"] = 0\n",
    "                df[\"if_long\"] = 0\n",
    "                df[\"long_target\"] = np.nan\n",
    "                df[\"short_target\"] = np.nan\n",
    "                df[\"long_stop_loss\"] = np.nan\n",
    "                df[\"short_stop_loss\"] = np.nan\n",
    "                df[\"shorts_win_after\"] = np.nan\n",
    "                df[\"longs_win_after\"] = np.nan\n",
    "#                 df[\"dual_loss\"] = 0\n",
    "#                 df[\"entered_before\"] = np.nan\n",
    "\n",
    "\n",
    "                # Calculate targets and stop losses, then determine wins and losses\n",
    "                for i in tqdm(range(len(df)), desc=f\"Processing {symbol}-{chart_time}\", unit='row'):\n",
    "                    if pd.notna(df.loc[i, 'entry']):\n",
    "                        long_target = df.loc[i, 'entry'] * (1 + win_perc / 100)\n",
    "                        long_stop_loss = df.loc[i, 'entry'] * (1 - loss_perc / 100)\n",
    "                        short_target = df.loc[i, 'entry'] * (1 - win_perc / 100)\n",
    "                        short_stop_loss = df.loc[i, 'entry'] * (1 + loss_perc / 100)\n",
    "\n",
    "                        # Initialize columns for current row\n",
    "                        df.loc[i, 'if_long'] = np.nan\n",
    "                        df.loc[i, 'longs_win_after'] = np.nan\n",
    "                        df.loc[i, 'if_short'] = np.nan\n",
    "                        df.loc[i, 'shorts_win_after'] = np.nan\n",
    "                        df.loc[i, 'dual_loss'] = 0\n",
    "                        df.loc[i, 'entered_before'] = np.nan\n",
    "                        df.loc[i, 'long_target'] = long_target\n",
    "                        df.loc[i, 'long_stop_loss'] = long_stop_loss\n",
    "                        df.loc[i, 'short_stop_loss'] = short_stop_loss\n",
    "                        \n",
    "\n",
    "                        # Evaluate long trades\n",
    "                        for j in range(i, len(df)):\n",
    "                            if df.loc[j, 'high'] >= long_target:\n",
    "                                if df.loc[j, 'low'] <= long_stop_loss:\n",
    "                                    df.loc[i, 'if_long'] = -1\n",
    "#                                     df.loc[i, 'dual_loss'] = 1\n",
    "#                                     df.loc[i, 'entered_before'] = j - i\n",
    "                                else:\n",
    "                                    df.loc[i, 'if_long'] = 1\n",
    "                                    df.loc[i, 'longs_win_after'] = j - i\n",
    "                                break\n",
    "                            elif df.loc[j, 'low'] <= long_stop_loss:\n",
    "                                df.loc[i, 'if_long'] = -1\n",
    "                                break\n",
    "                        df.loc[i, 'short_target'] = short_target\n",
    "                        # Evaluate short trades\n",
    "                        for j in range(i, len(df)):\n",
    "                            if df.loc[j, 'low'] <= short_target:\n",
    "                                if df.loc[j, 'high'] >= short_stop_loss:\n",
    "                                    df.loc[i, 'if_short'] = -1\n",
    "#                                     df.loc[i, 'dual_loss'] = 1\n",
    "#                                     df.loc[i, 'entered_before'] = j - i\n",
    "                                else:\n",
    "                                    df.loc[i, 'if_short'] = 1\n",
    "                                    df.loc[i, 'shorts_win_after'] = j - i\n",
    "                                break\n",
    "                            elif df.loc[j, 'high'] >= short_stop_loss:\n",
    "                                df.loc[i, 'if_short'] = -1\n",
    "                                break\n",
    "\n",
    "                # Save the processed data\n",
    "                df.to_csv(new_file_path, index=False)\n",
    "                print(f\"Processed file saved as {new_file_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {symbol} {chart_time}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6681a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wins_losses_optimized(master_dictionary, win_perc=0.73, loss_perc=0.4, lookahead_window=10000):\n",
    "    for symbol in master_dictionary[\"symbols\"]:\n",
    "        for chart_time in master_dictionary[\"chart_times\"]:\n",
    "            try:\n",
    "                print(f\"Calculating for {symbol} {chart_time}\")\n",
    "\n",
    "                # Define the directory for processed data\n",
    "                processed_data_dir = Path(output_dir) / f\"{symbol}-{chart_time}/processed_data\"\n",
    "\n",
    "                # Create the directory if it doesn't exist\n",
    "                processed_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Construct the file names\n",
    "                og_file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "                og_file_path = Path(output_dir) / f\"{symbol}-{chart_time}/{og_file_name}\"\n",
    "                new_file_name = f\"{symbol}-{chart_time}_W{win_perc}_L{loss_perc}.csv\"\n",
    "                new_file_path = processed_data_dir / new_file_name\n",
    "\n",
    "                # Read the CSV file into a dataframe\n",
    "                df = pd.read_csv(og_file_path)\n",
    "\n",
    "                # Initialize new columns\n",
    "                df[\"if_short\"] = np.nan\n",
    "                df[\"if_long\"] = np.nan\n",
    "                df[\"long_target\"] = df[\"entry\"] * (1 + win_perc / 100)\n",
    "                df[\"short_target\"] = df[\"entry\"] * (1 - win_perc / 100)\n",
    "                df[\"long_stop_loss\"] = df[\"entry\"] * (1 - loss_perc / 100)\n",
    "                df[\"short_stop_loss\"] = df[\"entry\"] * (1 + loss_perc / 100)\n",
    "                df[\"shorts_win_after\"] = np.nan\n",
    "                df[\"longs_win_after\"] = np.nan\n",
    "\n",
    "                # Convert DataFrame columns to numpy arrays for faster processing\n",
    "                highs = df['high'].values\n",
    "                lows = df['low'].values\n",
    "                long_targets = df['long_target'].values\n",
    "                short_targets = df['short_target'].values\n",
    "                long_stop_losses = df['long_stop_loss'].values\n",
    "                short_stop_losses = df['short_stop_loss'].values\n",
    "\n",
    "                # Define functions to compute win/loss results\n",
    "                def compute_win_loss(row):\n",
    "                    entry_idx = row.name\n",
    "                    # Define the lookahead window range\n",
    "                    lookahead_end = min(entry_idx + lookahead_window, len(df))\n",
    "                    \n",
    "                    # Slice the future highs and lows from current index onwards, respecting the lookahead window\n",
    "                    future_highs = highs[entry_idx:lookahead_end]\n",
    "                    future_lows = lows[entry_idx:lookahead_end]\n",
    "\n",
    "                    long_target_reached = np.argmax(future_highs >= row['long_target']) if np.any(future_highs >= row['long_target']) else np.nan\n",
    "                    long_stop_loss_reached = np.argmax(future_lows <= row['long_stop_loss']) if np.any(future_lows <= row['long_stop_loss']) else np.nan\n",
    "                    short_target_reached = np.argmax(future_lows <= row['short_target']) if np.any(future_lows <= row['short_target']) else np.nan\n",
    "                    short_stop_loss_reached = np.argmax(future_highs >= row['short_stop_loss']) if np.any(future_highs >= row['short_stop_loss']) else np.nan\n",
    "\n",
    "                    # Long trade logic\n",
    "                    if not np.isnan(long_target_reached) and (np.isnan(long_stop_loss_reached) or long_target_reached < long_stop_loss_reached):\n",
    "                        df.at[entry_idx, 'if_long'] = 1\n",
    "                        df.at[entry_idx, 'longs_win_after'] = long_target_reached\n",
    "                    elif not np.isnan(long_stop_loss_reached):\n",
    "                        df.at[entry_idx, 'if_long'] = -1\n",
    "\n",
    "                    # Short trade logic\n",
    "                    if not np.isnan(short_target_reached) and (np.isnan(short_stop_loss_reached) or short_target_reached < short_stop_loss_reached):\n",
    "                        df.at[entry_idx, 'if_short'] = 1\n",
    "                        df.at[entry_idx, 'shorts_win_after'] = short_target_reached\n",
    "                    elif not np.isnan(short_stop_loss_reached):\n",
    "                        df.at[entry_idx, 'if_short'] = -1\n",
    "\n",
    "                # Apply the function to each row with a progress bar\n",
    "                print(f\"Processing dataframe for {symbol}-{chart_time}...\")\n",
    "                tqdm.pandas(desc=f\"Processing Rows\")\n",
    "                df.progress_apply(compute_win_loss, axis=1)\n",
    "\n",
    "                # Save the processed data\n",
    "                df.to_csv(new_file_path, index=False)\n",
    "                print(f\"Processed file saved as {new_file_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {symbol} {chart_time}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7952c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wins_losses_optimized_big_timeframes(master_dictionary, win_perc=0.73, loss_perc=0.4):\n",
    "    for symbol in master_dictionary[\"symbols\"]:\n",
    "        for chart_time in master_dictionary[\"chart_times\"]:\n",
    "            try:\n",
    "                print(f\"Calculating for {symbol} {chart_time}\")\n",
    "\n",
    "                # Define the directory for processed data\n",
    "                processed_data_dir = Path(output_dir) / f\"{symbol}-{chart_time}/processed_data\"\n",
    "                processed_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Construct the file names\n",
    "                og_file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "                og_file_path = Path(output_dir) / f\"{symbol}-{chart_time}/{og_file_name}\"\n",
    "                new_file_name = f\"{symbol}-{chart_time}_W{win_perc}_L{loss_perc}.csv\"\n",
    "                new_file_path = processed_data_dir / new_file_name\n",
    "\n",
    "                # Read the CSV file into a dataframe\n",
    "                df = pd.read_csv(og_file_path)\n",
    "\n",
    "                # Initialize new columns\n",
    "                df[\"if_short\"] = np.nan\n",
    "                df[\"if_long\"] = np.nan\n",
    "                df[\"long_target\"] = df[\"entry\"] * (1 + win_perc / 100)\n",
    "                df[\"short_target\"] = df[\"entry\"] * (1 - win_perc / 100)\n",
    "                df[\"long_stop_loss\"] = df[\"entry\"] * (1 - loss_perc / 100)\n",
    "                df[\"short_stop_loss\"] = df[\"entry\"] * (1 + loss_perc / 100)\n",
    "                df[\"shorts_win_after\"] = np.nan\n",
    "                df[\"longs_win_after\"] = np.nan\n",
    "\n",
    "                # Compute targets and stop losses\n",
    "                high = df['high'].values\n",
    "                low = df['low'].values\n",
    "                long_targets = df['long_target'].values\n",
    "                long_stop_losses = df['long_stop_loss'].values\n",
    "                short_targets = df['short_target'].values\n",
    "                short_stop_losses = df['short_stop_loss'].values\n",
    "\n",
    "                # Use tqdm for progress tracking\n",
    "                print(f\"Processing dataframe for {symbol}-{chart_time}...\")\n",
    "                for entry_idx in tqdm(range(len(df)), desc=\"Processing Rows\", unit='row'):\n",
    "                    long_target_reached = np.nan\n",
    "                    long_stop_loss_reached = np.nan\n",
    "                    short_target_reached = np.nan\n",
    "                    short_stop_loss_reached = np.nan\n",
    "\n",
    "                    if not np.isnan(long_targets[entry_idx]):\n",
    "                        future_high = high[entry_idx:]\n",
    "                        if np.any(future_high >= long_targets[entry_idx]):\n",
    "                            long_target_reached = np.where(future_high >= long_targets[entry_idx])[0][0] + entry_idx\n",
    "                        if np.any(low[entry_idx:] <= long_stop_losses[entry_idx]):\n",
    "                            long_stop_loss_reached = np.where(low[entry_idx:] <= long_stop_losses[entry_idx])[0][0] + entry_idx\n",
    "\n",
    "                    if not np.isnan(short_targets[entry_idx]):\n",
    "                        future_low = low[entry_idx:]\n",
    "                        if np.any(future_low <= short_targets[entry_idx]):\n",
    "                            short_target_reached = np.where(future_low <= short_targets[entry_idx])[0][0] + entry_idx\n",
    "                        if np.any(high[entry_idx:] >= short_stop_losses[entry_idx]):\n",
    "                            short_stop_loss_reached = np.where(high[entry_idx:] >= short_stop_losses[entry_idx])[0][0] + entry_idx\n",
    "\n",
    "                    # Update DataFrame based on computed values\n",
    "                    if long_target_reached is not np.nan and (np.isnan(long_stop_loss_reached) or long_target_reached < long_stop_loss_reached):\n",
    "                        df.at[entry_idx, 'if_long'] = 1\n",
    "                        df.at[entry_idx, 'longs_win_after'] = long_target_reached - entry_idx\n",
    "                    elif long_stop_loss_reached is not np.nan:\n",
    "                        df.at[entry_idx, 'if_long'] = -1\n",
    "\n",
    "                    if short_target_reached is not np.nan and (np.isnan(short_stop_loss_reached) or short_target_reached < short_stop_loss_reached):\n",
    "                        df.at[entry_idx, 'if_short'] = 1\n",
    "                        df.at[entry_idx, 'shorts_win_after'] = short_target_reached - entry_idx\n",
    "                    elif short_stop_loss_reached is not np.nan:\n",
    "                        df.at[entry_idx, 'if_short'] = -1\n",
    "\n",
    "                # Save the processed data\n",
    "                df.to_csv(new_file_path, index=False)\n",
    "                print(f\"Processed file saved as {new_file_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {symbol} {chart_time}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf07cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wins_losses_optimized_yotpaaaaa(master_dictionary, win_perc=0.73, loss_perc=0.4):\n",
    "    for symbol in master_dictionary[\"symbols\"]:\n",
    "        for chart_time in master_dictionary[\"chart_times\"]:\n",
    "            try:\n",
    "                print(f\"Calculating for {symbol} {chart_time}\")\n",
    "\n",
    "                # Define the directory for processed data\n",
    "                processed_data_dir = Path(output_dir) / f\"{symbol}-{chart_time}/processed_data\"\n",
    "                processed_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Construct the file names\n",
    "                og_file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "                og_file_path = Path(output_dir) / f\"{symbol}-{chart_time}/{og_file_name}\"\n",
    "                new_file_name = f\"{symbol}-{chart_time}_W{win_perc}_L{loss_perc}.csv\"\n",
    "                new_file_path = processed_data_dir / new_file_name\n",
    "\n",
    "                # Read the CSV file into a dataframe\n",
    "                df = pd.read_csv(og_file_path)\n",
    "\n",
    "                # Initialize new columns\n",
    "                df[\"if_short\"] = np.nan\n",
    "                df[\"if_long\"] = np.nan\n",
    "                df[\"long_target\"] = df[\"entry\"] * (1 + win_perc / 100)\n",
    "                df[\"short_target\"] = df[\"entry\"] * (1 - win_perc / 100)\n",
    "                df[\"long_stop_loss\"] = df[\"entry\"] * (1 - loss_perc / 100)\n",
    "                df[\"short_stop_loss\"] = df[\"entry\"] * (1 + loss_perc / 100)\n",
    "                df[\"shorts_win_after\"] = np.nan\n",
    "                df[\"longs_win_after\"] = np.nan\n",
    "\n",
    "                # Convert columns to numpy arrays for faster indexing\n",
    "                high = df['high'].values\n",
    "                low = df['low'].values\n",
    "                long_targets = df['long_target'].values\n",
    "                long_stop_losses = df['long_stop_loss'].values\n",
    "                short_targets = df['short_target'].values\n",
    "                short_stop_losses = df['short_stop_loss'].values\n",
    "\n",
    "                # Efficiently process each row\n",
    "                for entry_idx in tqdm(range(len(df)), desc=\"Processing Rows\", unit='row'):\n",
    "                    long_target_reached = np.nan\n",
    "                    long_stop_loss_reached = np.nan\n",
    "                    short_target_reached = np.nan\n",
    "                    short_stop_loss_reached = np.nan\n",
    "\n",
    "                    if not np.isnan(long_targets[entry_idx]):\n",
    "                        future_high = high[entry_idx:]\n",
    "                        long_target_reached = np.argmax(future_high >= long_targets[entry_idx]) + entry_idx if np.any(future_high >= long_targets[entry_idx]) else np.nan\n",
    "                        long_stop_loss_reached = np.argmax(low[entry_idx:] <= long_stop_losses[entry_idx]) + entry_idx if np.any(low[entry_idx:] <= long_stop_losses[entry_idx]) else np.nan\n",
    "\n",
    "                    if not np.isnan(short_targets[entry_idx]):\n",
    "                        future_low = low[entry_idx:]\n",
    "                        short_target_reached = np.argmax(future_low <= short_targets[entry_idx]) + entry_idx if np.any(future_low <= short_targets[entry_idx]) else np.nan\n",
    "                        short_stop_loss_reached = np.argmax(high[entry_idx:] >= short_stop_losses[entry_idx]) + entry_idx if np.any(high[entry_idx:] >= short_stop_losses[entry_idx]) else np.nan\n",
    "\n",
    "                    # Update DataFrame based on computed values\n",
    "                    if not np.isnan(long_target_reached) and (np.isnan(long_stop_loss_reached) or long_target_reached < long_stop_loss_reached):\n",
    "                        df.at[entry_idx, 'if_long'] = 1\n",
    "                        df.at[entry_idx, 'longs_win_after'] = long_target_reached - entry_idx\n",
    "                    elif not np.isnan(long_stop_loss_reached):\n",
    "                        df.at[entry_idx, 'if_long'] = -1\n",
    "\n",
    "                    if not np.isnan(short_target_reached) and (np.isnan(short_stop_loss_reached) or short_target_reached < short_stop_loss_reached):\n",
    "                        df.at[entry_idx, 'if_short'] = 1\n",
    "                        df.at[entry_idx, 'shorts_win_after'] = short_target_reached - entry_idx\n",
    "                    elif not np.isnan(short_stop_loss_reached):\n",
    "                        df.at[entry_idx, 'if_short'] = -1\n",
    "\n",
    "                # Save the processed data\n",
    "                df.to_csv(new_file_path, index=False)\n",
    "                print(f\"Processed file saved as {new_file_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {symbol} {chart_time}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81af2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wins_losses_optimized(master_dictionary, win_perc=0.73, loss_perc=0.4):\n",
    "    for symbol in master_dictionary[\"symbols\"]:\n",
    "        for chart_time in master_dictionary[\"chart_times\"]:\n",
    "            try:\n",
    "                print(f\"Calculating for {symbol} {chart_time}\")\n",
    "                \n",
    "                # Define the directory for processed data\n",
    "                processed_data_dir = Path(output_dir) / f\"{symbol}-{chart_time}/processed_data\"\n",
    "                processed_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # Construct the file names\n",
    "                og_file_path = Path(output_dir) / f\"{symbol}-{chart_time}/{symbol}-{chart_time}.csv\"\n",
    "                new_file_path = processed_data_dir / f\"{symbol}-{chart_time}_W{win_perc}_L{loss_perc}.csv\"\n",
    "                \n",
    "                # Read the CSV file into a dataframe\n",
    "                df = pd.read_csv(og_file_path)\n",
    "                \n",
    "                # Calculate targets and stop losses\n",
    "                df[\"entry\"] = df[\"open\"]\n",
    "                df[\"long_target\"] = df[\"entry\"] * (1 + win_perc / 100)\n",
    "                df[\"short_target\"] = df[\"entry\"] * (1 - win_perc / 100)\n",
    "                df[\"long_stop_loss\"] = df[\"entry\"] * (1 - loss_perc / 100)\n",
    "                df[\"short_stop_loss\"] = df[\"entry\"] * (1 + loss_perc / 100)\n",
    "                \n",
    "                print(f\"Processing dataframe for {symbol}-{chart_time}...\")\n",
    "                \n",
    "                # Initialize result columns\n",
    "                df['if_long'] = np.nan\n",
    "                df['if_short'] = np.nan\n",
    "                df['longs_win_after'] = np.nan\n",
    "                df['shorts_win_after'] = np.nan\n",
    "                \n",
    "                # Compute cumulative max and min\n",
    "                df['cum_max_high'] = df['high'].cummax()\n",
    "                df['cum_min_low'] = df['low'].cummin()\n",
    "                \n",
    "                # Compute long trade outcomes\n",
    "                long_target_reached = df['cum_max_high'] >= df['long_target']\n",
    "                long_stop_loss_reached = df['cum_min_low'] <= df['long_stop_loss']\n",
    "                df.loc[long_target_reached & ~long_stop_loss_reached, 'if_long'] = 1  # Win\n",
    "                df.loc[long_stop_loss_reached, 'if_long'] = -1  # Loss\n",
    "                \n",
    "                # Compute short trade outcomes\n",
    "                short_target_reached = df['cum_min_low'] <= df['short_target']\n",
    "                short_stop_loss_reached = df['cum_max_high'] >= df['short_stop_loss']\n",
    "                df.loc[short_target_reached & ~short_stop_loss_reached, 'if_short'] = 1  # Win\n",
    "                df.loc[short_stop_loss_reached, 'if_short'] = -1  # Loss\n",
    "                \n",
    "                # Calculate win_after values for long trades\n",
    "                df['longs_win_after'] = np.nan\n",
    "                for i in df.index[df['if_long'] == 1]:\n",
    "                    subsequent_target_hits = df.loc[i:]['cum_max_high'] >= df.loc[i, 'long_target']\n",
    "                    if subsequent_target_hits.any():\n",
    "                        df.loc[i, 'longs_win_after'] = subsequent_target_hits.idxmax() - i\n",
    "                \n",
    "                # Calculate win_after values for short trades\n",
    "                df['shorts_win_after'] = np.nan\n",
    "                for i in df.index[df['if_short'] == 1]:\n",
    "                    subsequent_target_hits = df.loc[i:]['cum_min_low'] <= df.loc[i, 'short_target']\n",
    "                    if subsequent_target_hits.any():\n",
    "                        df.loc[i, 'shorts_win_after'] = subsequent_target_hits.idxmax() - i\n",
    "                \n",
    "                # Drop intermediate columns\n",
    "                df = df.drop(['cum_max_high', 'cum_min_low'], axis=1)\n",
    "                \n",
    "                # Save the processed data\n",
    "                df.to_csv(new_file_path, index=False)\n",
    "                print(f\"Processed file saved as {new_file_path.name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {symbol} {chart_time}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wins_losses_batched(master_dictionary, win_perc=0.73, loss_perc=0.4, batch_size=5000):\n",
    "    for symbol in master_dictionary[\"symbols\"]:\n",
    "        for chart_time in master_dictionary[\"chart_times\"]:\n",
    "            try:\n",
    "                print(f\"Calculating for {symbol} {chart_time}\")\n",
    "\n",
    "                # Define the directory for processed data\n",
    "                processed_data_dir = Path(output_dir) / f\"{symbol}-{chart_time}/processed_data\"\n",
    "                processed_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Construct file paths\n",
    "                og_file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "                og_file_path = Path(output_dir) / f\"{symbol}-{chart_time}/{og_file_name}\"\n",
    "                new_file_name = f\"{symbol}-{chart_time}_W{win_perc}_L{loss_perc}.csv\"\n",
    "                new_file_path = processed_data_dir / new_file_name\n",
    "\n",
    "                # Read the CSV file into a dataframe\n",
    "                df = pd.read_csv(og_file_path)\n",
    "\n",
    "                # Initialize new columns\n",
    "                df[\"if_short\"] = np.nan\n",
    "                df[\"if_long\"] = np.nan\n",
    "                df[\"long_target\"] = df[\"entry\"] * (1 + win_perc / 100)\n",
    "                df[\"short_target\"] = df[\"entry\"] * (1 - win_perc / 100)\n",
    "                df[\"long_stop_loss\"] = df[\"entry\"] * (1 - loss_perc / 100)\n",
    "                df[\"short_stop_loss\"] = df[\"entry\"] * (1 + loss_perc / 100)\n",
    "                df[\"shorts_win_after\"] = np.nan\n",
    "                df[\"longs_win_after\"] = np.nan\n",
    "\n",
    "                # Convert DataFrame columns to numpy arrays for faster processing\n",
    "                highs = df['high'].values\n",
    "                lows = df['low'].values\n",
    "                long_targets = df['long_target'].values\n",
    "                short_targets = df['short_target'].values\n",
    "                long_stop_losses = df['long_stop_loss'].values\n",
    "                short_stop_losses = df['short_stop_loss'].values\n",
    "\n",
    "                # Process entries in batches\n",
    "                for i in tqdm(range(0, len(df), batch_size), desc=f\"Processing batches for {symbol}-{chart_time}\", unit='row'):\n",
    "                    batch_highs = highs[i:i+batch_size]\n",
    "                    batch_lows = lows[i:i+batch_size]\n",
    "                    batch_size_current = len(batch_highs)\n",
    "\n",
    "                    for j in range(batch_size_current):\n",
    "                        idx = i + j  # Global index in the main dataframe\n",
    "                        \n",
    "                        future_highs = highs[idx:]\n",
    "                        future_lows = lows[idx:]\n",
    "\n",
    "                        # Long trade logic\n",
    "                        long_hit_idx = np.argmax(future_highs >= long_targets[idx]) if np.any(future_highs >= long_targets[idx]) else np.nan\n",
    "                        long_stop_idx = np.argmax(future_lows <= long_stop_losses[idx]) if np.any(future_lows <= long_stop_losses[idx]) else np.nan\n",
    "\n",
    "                        if not np.isnan(long_hit_idx) and (np.isnan(long_stop_idx) or long_hit_idx < long_stop_idx):\n",
    "                            df.at[idx, 'if_long'] = 1\n",
    "                            df.at[idx, 'longs_win_after'] = long_hit_idx\n",
    "                        elif not np.isnan(long_stop_idx):\n",
    "                            df.at[idx, 'if_long'] = -1\n",
    "\n",
    "                        # Short trade logic\n",
    "                        short_hit_idx = np.argmax(future_lows <= short_targets[idx]) if np.any(future_lows <= short_targets[idx]) else np.nan\n",
    "                        short_stop_idx = np.argmax(future_highs >= short_stop_losses[idx]) if np.any(future_highs >= short_stop_losses[idx]) else np.nan\n",
    "\n",
    "                        if not np.isnan(short_hit_idx) and (np.isnan(short_stop_idx) or short_hit_idx < short_stop_idx):\n",
    "                            df.at[idx, 'if_short'] = 1\n",
    "                            df.at[idx, 'shorts_win_after'] = short_hit_idx\n",
    "                        elif not np.isnan(short_stop_idx):\n",
    "                            df.at[idx, 'if_short'] = -1\n",
    "\n",
    "                # Save the processed data\n",
    "                df.to_csv(new_file_path, index=False)\n",
    "                print(f\"Processed file saved as {new_file_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {symbol} {chart_time}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f007349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wins_losses_optimized_yotpa(master_dictionary, lookahead_window=10000, win_perc=0.73, loss_perc=0.4):\n",
    "    for symbol in master_dictionary[\"symbols\"]:\n",
    "        for chart_time in master_dictionary[\"chart_times\"]:\n",
    "            try:\n",
    "                print(f\"Calculating for {symbol} {chart_time}\")\n",
    "\n",
    "                # Define the directory for processed data\n",
    "                processed_data_dir = Path(output_dir) / f\"{symbol}-{chart_time}/processed_data\"\n",
    "\n",
    "                # Create the directory if it doesn't exist\n",
    "                processed_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Construct the file names\n",
    "                og_file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "                og_file_path = Path(output_dir) / f\"{symbol}-{chart_time}/{og_file_name}\"\n",
    "                new_file_name = f\"{symbol}-{chart_time}_W{win_perc}_L{loss_perc}.csv\"\n",
    "                new_file_path = processed_data_dir / new_file_name\n",
    "\n",
    "                # Read the CSV file into a dataframe\n",
    "                df = pd.read_csv(og_file_path)\n",
    "\n",
    "                # Initialize new columns\n",
    "                df[\"if_short\"] = np.nan\n",
    "                df[\"if_long\"] = np.nan\n",
    "                df[\"long_target\"] = df[\"entry\"] * (1 + win_perc / 100)\n",
    "                df[\"short_target\"] = df[\"entry\"] * (1 - win_perc / 100)\n",
    "                df[\"long_stop_loss\"] = df[\"entry\"] * (1 - loss_perc / 100)\n",
    "                df[\"short_stop_loss\"] = df[\"entry\"] * (1 + loss_perc / 100)\n",
    "                df[\"shorts_win_after\"] = np.nan\n",
    "                df[\"longs_win_after\"] = np.nan\n",
    "\n",
    "                # Convert DataFrame columns to numpy arrays for faster processing\n",
    "                highs = df['high'].values\n",
    "                lows = df['low'].values\n",
    "                long_targets = df['long_target'].values\n",
    "                short_targets = df['short_target'].values\n",
    "                long_stop_losses = df['long_stop_loss'].values\n",
    "                short_stop_losses = df['short_stop_loss'].values\n",
    "\n",
    "                # Process each entry row by row\n",
    "                for i in tqdm(range(len(df)), desc=\"Processing Rows\", unit='row'):\n",
    "                    # Slice the future highs and lows from current index onwards\n",
    "                    lookahead_end = min(i + lookahead_window, len(df))\n",
    "                    \n",
    "                    # Slice the future highs and lows from current index onwards, respecting the lookahead window\n",
    "                    future_highs = highs[i:lookahead_end]\n",
    "                    future_lows = lows[i:lookahead_end]\n",
    "\n",
    "                    # Early stopping for performance improvement\n",
    "                    long_hit_idx = np.argmax(future_highs >= long_targets[i]) if np.any(future_highs >= long_targets[i]) else np.nan\n",
    "                    long_stop_idx = np.argmax(future_lows <= long_stop_losses[i]) if np.any(future_lows <= long_stop_losses[i]) else np.nan\n",
    "\n",
    "                    short_hit_idx = np.argmax(future_lows <= short_targets[i]) if np.any(future_lows <= short_targets[i]) else np.nan\n",
    "                    short_stop_idx = np.argmax(future_highs >= short_stop_losses[i]) if np.any(future_highs >= short_stop_losses[i]) else np.nan\n",
    "\n",
    "                    # Long trade logic\n",
    "                    if not np.isnan(long_hit_idx) and (np.isnan(long_stop_idx) or long_hit_idx < long_stop_idx):\n",
    "                        df.at[i, 'if_long'] = 1\n",
    "                        df.at[i, 'longs_win_after'] = long_hit_idx\n",
    "                    elif not np.isnan(long_stop_idx):\n",
    "                        df.at[i, 'if_long'] = -1\n",
    "\n",
    "                    # Short trade logic\n",
    "                    if not np.isnan(short_hit_idx) and (np.isnan(short_stop_idx) or short_hit_idx < short_stop_idx):\n",
    "                        df.at[i, 'if_short'] = 1\n",
    "                        df.at[i, 'shorts_win_after'] = short_hit_idx\n",
    "                    elif not np.isnan(short_stop_idx):\n",
    "                        df.at[i, 'if_short'] = -1\n",
    "\n",
    "                # Save the processed data\n",
    "                df.to_csv(new_file_path, index=False)\n",
    "                print(f\"Processed file saved as {new_file_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {symbol} {chart_time}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c0ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_indicators_using_talib(timeperiods, df):\n",
    "    new_columns = pd.DataFrame()\n",
    "\n",
    "    # List to store indicator columns\n",
    "    indicator_columns = []\n",
    "    indicator_columns.append(('HT_TRENDLINE', talib.HT_TRENDLINE(df['close'])))\n",
    "    # indicator_columns.append(('MAMA', df['MAMA']), ('FAMA', df['FAMA']))\n",
    "    # indicator_columns.append(('MAVP', df['MAVP']))\n",
    "    indicator_columns.append(\n",
    "        ('SAR', talib.SAR(df['high'], df['low'], acceleration=0, maximum=0)))\n",
    "    indicator_columns.append(('SAREXT', talib.SAREXT(df['high'], df['low'])))\n",
    "    indicator_columns.append(\n",
    "        ('T3', talib.T3(df['close'], timeperiod=5, vfactor=0)))\n",
    "    # Momentum Indicators\n",
    "    indicator_columns.append(\n",
    "        ('APO', talib.APO(df['close'], fastperiod=12, slowperiod=26)))\n",
    "    indicator_columns.append(\n",
    "        ('BOP', talib.BOP(df['open'], df['high'], df['low'], df['close'])))\n",
    "    macd, macd_signal, macd_hist = talib.MACD(df['close'],\n",
    "                                              fastperiod=12,\n",
    "                                              slowperiod=26,\n",
    "                                              signalperiod=9)\n",
    "    indicator_columns.append(('MACD', macd))\n",
    "    indicator_columns.append(('MACD_signal', macd_signal))\n",
    "    indicator_columns.append(('MACD_hist', macd_hist))\n",
    "    indicator_columns.append(\n",
    "        ('PPO', talib.PPO(df['close'], fastperiod=12, slowperiod=26,\n",
    "                          matype=0)))\n",
    "    indicator_columns.append(('TRIX', talib.TRIX(df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('ULTOSC', talib.ULTOSC(df['high'], df['low'], df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('WILLR', talib.WILLR(df['high'], df['low'], df['close'])))\n",
    "\n",
    "    #     # Not Working ATM\n",
    "    #     indicator_columns.append(('STOCH', talib.STOCH(df['high'], df['low'], df['close'])))\n",
    "    #     indicator_columns.append(('STOCHF', talib.STOCHF(df['high'], df['low'], df['close'])))\n",
    "    #     indicator_columns.append(('STOCHRSI', talib.STOCHRSI(df['close'])))\n",
    "    #     indicator_columns.append(('MACDEXT', talib.MACDEXT(df['close'], fastperiod=12, fastmatype=0, slowperiod=26, slowmatype=0, signalperiod=9, signalmatype=0)))\n",
    "    #     indicator_columns.append(('MACDFIX', talib.MACDFIX(df['close'], signalperiod=9)))\n",
    "\n",
    "    #########Volume Indicators\n",
    "    indicator_columns.append(\n",
    "        ('AD', talib.AD(df['high'], df['low'], df['close'], df['volume'])))\n",
    "    indicator_columns.append(('ADOSC',\n",
    "                              talib.ADOSC(df['high'],\n",
    "                                          df['low'],\n",
    "                                          df['close'],\n",
    "                                          df['volume'],\n",
    "                                          fastperiod=3,\n",
    "                                          slowperiod=10)))\n",
    "    indicator_columns.append(('OBV', talib.OBV(df['close'], df['volume'])))\n",
    "\n",
    "    #########Cycle Indicators\n",
    "    indicator_columns.append(('HT_DCPERIOD', talib.HT_DCPERIOD(df['close'])))\n",
    "    indicator_columns.append(('HT_DCPHASE', talib.HT_DCPHASE(df['close'])))\n",
    "    phasor_inphase, phasor_quadrature = talib.HT_PHASOR(df['close'])\n",
    "    indicator_columns.append(('HT_PHASOR_inphase', phasor_inphase))\n",
    "    indicator_columns.append(('HT_PHASOR_quadrature', phasor_quadrature))\n",
    "    # indicator_columns.append(('HT_SINE', talib.HT_SINE(df['close'])))\n",
    "    indicator_columns.append(('HT_TRENDMODE', talib.HT_TRENDMODE(df['close'])))\n",
    "\n",
    "    #########Price Transform\n",
    "    indicator_columns.append(('AVGPRICE',\n",
    "                              talib.AVGPRICE(df['open'], df['high'], df['low'],\n",
    "                                             df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('MEDPRICE', talib.MEDPRICE(df['high'], df['low'])))\n",
    "    indicator_columns.append(\n",
    "        ('TYPPRICE', talib.TYPPRICE(df['high'], df['low'], df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('WCLPRICE', talib.WCLPRICE(df['high'], df['low'], df['close'])))\n",
    "    #########Volatility Indicators\n",
    "    indicator_columns.append(\n",
    "        ('TRANGE', talib.TRANGE(df['high'], df['low'], df['close'])))\n",
    "    #########Pattern Recognition\n",
    "    indicator_columns.append(('CDL2CROWS',\n",
    "                              talib.CDL2CROWS(df['open'], df['high'],\n",
    "                                              df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDL3BLACKCROWS',\n",
    "                              talib.CDL3BLACKCROWS(df['open'], df['high'],\n",
    "                                                   df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDL3INSIDE',\n",
    "                              talib.CDL3INSIDE(df['open'], df['high'],\n",
    "                                               df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDL3LINESTRIKE',\n",
    "                              talib.CDL3LINESTRIKE(df['open'], df['high'],\n",
    "                                                   df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDL3OUTSIDE',\n",
    "                              talib.CDL3OUTSIDE(df['open'], df['high'],\n",
    "                                                df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDL3STARSINSOUTH',\n",
    "                              talib.CDL3STARSINSOUTH(df['open'], df['high'],\n",
    "                                                     df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDL3WHITESOLDIERS',\n",
    "                              talib.CDL3WHITESOLDIERS(df['open'], df['high'],\n",
    "                                                      df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLABANDONEDBABY',\n",
    "                              talib.CDLABANDONEDBABY(df['open'],\n",
    "                                                     df['high'],\n",
    "                                                     df['low'],\n",
    "                                                     df['close'],\n",
    "                                                     penetration=0)))\n",
    "\n",
    "    indicator_columns.append(('CDLADVANCEBLOCK',\n",
    "                              talib.CDLADVANCEBLOCK(df['open'], df['high'],\n",
    "                                                    df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLBELTHOLD',\n",
    "                              talib.CDLBELTHOLD(df['open'], df['high'],\n",
    "                                                df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLBREAKAWAY',\n",
    "                              talib.CDLBREAKAWAY(df['open'], df['high'],\n",
    "                                                 df['low'], df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('CDLCLOSINGMARUBOZU',\n",
    "         talib.CDLCLOSINGMARUBOZU(df['open'], df['high'], df['low'],\n",
    "                                  df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('CDLCONCEALBABYSWALL',\n",
    "         talib.CDLCONCEALBABYSWALL(df['open'], df['high'], df['low'],\n",
    "                                   df['close'])))\n",
    "    indicator_columns.append(('CDLCOUNTERATTACK',\n",
    "                              talib.CDLCOUNTERATTACK(df['open'], df['high'],\n",
    "                                                     df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLDARKCLOUDCOVER',\n",
    "                              talib.CDLDARKCLOUDCOVER(df['open'],\n",
    "                                                      df['high'],\n",
    "                                                      df['low'],\n",
    "                                                      df['close'],\n",
    "                                                      penetration=0)))\n",
    "\n",
    "    indicator_columns.append(('CDLDOJI',\n",
    "                              talib.CDLDOJI(df['open'], df['high'], df['low'],\n",
    "                                            df['close'])))\n",
    "    indicator_columns.append(('CDLDOJISTAR',\n",
    "                              talib.CDLDOJISTAR(df['open'], df['high'],\n",
    "                                                df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLDRAGONFLYDOJI',\n",
    "                              talib.CDLDRAGONFLYDOJI(df['open'], df['high'],\n",
    "                                                     df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLENGULFING',\n",
    "                              talib.CDLENGULFING(df['open'], df['high'],\n",
    "                                                 df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLEVENINGDOJISTAR',\n",
    "                              talib.CDLEVENINGDOJISTAR(df['open'],\n",
    "                                                       df['high'],\n",
    "                                                       df['low'],\n",
    "                                                       df['close'],\n",
    "                                                       penetration=0)))\n",
    "\n",
    "    indicator_columns.append(('CDLEVENINGSTAR',\n",
    "                              talib.CDLEVENINGSTAR(df['open'],\n",
    "                                                   df['high'],\n",
    "                                                   df['low'],\n",
    "                                                   df['close'],\n",
    "                                                   penetration=0)))\n",
    "    indicator_columns.append(\n",
    "        ('CDLGAPSIDESIDEWHITE',\n",
    "         talib.CDLGAPSIDESIDEWHITE(df['open'], df['high'], df['low'],\n",
    "                                   df['close'])))\n",
    "    indicator_columns.append(('CDLGRAVESTONEDOJI',\n",
    "                              talib.CDLGRAVESTONEDOJI(df['open'], df['high'],\n",
    "                                                      df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLHAMMER',\n",
    "                              talib.CDLHAMMER(df['open'], df['high'],\n",
    "                                              df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLHANGINGMAN',\n",
    "                              talib.CDLHANGINGMAN(df['open'], df['high'],\n",
    "                                                  df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLHARAMI',\n",
    "                              talib.CDLHARAMI(df['open'], df['high'],\n",
    "                                              df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLHARAMICROSS',\n",
    "                              talib.CDLHARAMICROSS(df['open'], df['high'],\n",
    "                                                   df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLHIGHWAVE',\n",
    "                              talib.CDLHIGHWAVE(df['open'], df['high'],\n",
    "                                                df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLHIKKAKE',\n",
    "                              talib.CDLHIKKAKE(df['open'], df['high'],\n",
    "                                               df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLHIKKAKEMOD',\n",
    "                              talib.CDLHIKKAKEMOD(df['open'], df['high'],\n",
    "                                                  df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLHOMINGPIGEON',\n",
    "                              talib.CDLHOMINGPIGEON(df['open'], df['high'],\n",
    "                                                    df['low'], df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('CDLIDENTICAL3CROWS',\n",
    "         talib.CDLIDENTICAL3CROWS(df['open'], df['high'], df['low'],\n",
    "                                  df['close'])))\n",
    "    indicator_columns.append(('CDLINNECK',\n",
    "                              talib.CDLINNECK(df['open'], df['high'],\n",
    "                                              df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLINVERTEDHAMMER',\n",
    "                              talib.CDLINVERTEDHAMMER(df['open'], df['high'],\n",
    "                                                      df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLKICKING',\n",
    "                              talib.CDLKICKING(df['open'], df['high'],\n",
    "                                               df['low'], df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('CDLKICKINGBYLENGTH',\n",
    "         talib.CDLKICKINGBYLENGTH(df['open'], df['high'], df['low'],\n",
    "                                  df['close'])))\n",
    "    indicator_columns.append(('CDLLADDERBOTTOM',\n",
    "                              talib.CDLLADDERBOTTOM(df['open'], df['high'],\n",
    "                                                    df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLLONGLEGGEDDOJI',\n",
    "                              talib.CDLLONGLEGGEDDOJI(df['open'], df['high'],\n",
    "                                                      df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLLONGLINE',\n",
    "                              talib.CDLLONGLINE(df['open'], df['high'],\n",
    "                                                df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLMARUBOZU',\n",
    "                              talib.CDLMARUBOZU(df['open'], df['high'],\n",
    "                                                df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLMATCHINGLOW',\n",
    "                              talib.CDLMATCHINGLOW(df['open'], df['high'],\n",
    "                                                   df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLMATHOLD',\n",
    "                              talib.CDLMATHOLD(df['open'],\n",
    "                                               df['high'],\n",
    "                                               df['low'],\n",
    "                                               df['close'],\n",
    "                                               penetration=0)))\n",
    "    indicator_columns.append(\n",
    "        ('CDLMORNINGDOJISTAR',\n",
    "         talib.CDLMORNINGDOJISTAR(df['open'], df['high'], df['low'],\n",
    "                                  df['close'])))\n",
    "    indicator_columns.append(('CDLMORNINGSTAR',\n",
    "                              talib.CDLMORNINGSTAR(df['open'], df['high'],\n",
    "                                                   df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLONNECK',\n",
    "                              talib.CDLONNECK(df['open'], df['high'],\n",
    "                                              df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLPIERCING',\n",
    "                              talib.CDLPIERCING(df['open'], df['high'],\n",
    "                                                df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLRICKSHAWMAN',\n",
    "                              talib.CDLRICKSHAWMAN(df['open'], df['high'],\n",
    "                                                   df['low'], df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('CDLRISEFALL3METHODS',\n",
    "         talib.CDLRISEFALL3METHODS(df['open'], df['high'], df['low'],\n",
    "                                   df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('CDLSEPARATINGLINES',\n",
    "         talib.CDLSEPARATINGLINES(df['open'], df['high'], df['low'],\n",
    "                                  df['close'])))\n",
    "    indicator_columns.append(('CDLSHOOTINGSTAR',\n",
    "                              talib.CDLSHOOTINGSTAR(df['open'], df['high'],\n",
    "                                                    df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLSHORTLINE',\n",
    "                              talib.CDLSHORTLINE(df['open'], df['high'],\n",
    "                                                 df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLSPINNINGTOP',\n",
    "                              talib.CDLSPINNINGTOP(df['open'], df['high'],\n",
    "                                                   df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLSTALLEDPATTERN',\n",
    "                              talib.CDLSTALLEDPATTERN(df['open'], df['high'],\n",
    "                                                      df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLSTICKSANDWICH',\n",
    "                              talib.CDLSTICKSANDWICH(df['open'], df['high'],\n",
    "                                                     df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLTAKURI',\n",
    "                              talib.CDLTAKURI(df['open'], df['high'],\n",
    "                                              df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLTASUKIGAP',\n",
    "                              talib.CDLTASUKIGAP(df['open'], df['high'],\n",
    "                                                 df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLTHRUSTING',\n",
    "                              talib.CDLTHRUSTING(df['open'], df['high'],\n",
    "                                                 df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLTRISTAR',\n",
    "                              talib.CDLTRISTAR(df['open'], df['high'],\n",
    "                                               df['low'], df['close'])))\n",
    "    indicator_columns.append(('CDLUNIQUE3RIVER',\n",
    "                              talib.CDLUNIQUE3RIVER(df['open'], df['high'],\n",
    "                                                    df['low'], df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('CDLUPSIDEGAP2CROWS',\n",
    "         talib.CDLUPSIDEGAP2CROWS(df['open'], df['high'], df['low'],\n",
    "                                  df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('CDLXSIDEGAP3METHODS',\n",
    "         talib.CDLXSIDEGAP3METHODS(df['open'], df['high'], df['low'],\n",
    "                                   df['close'])))\n",
    "    #########Statistic Functions\n",
    "    indicator_columns.append(('LINEARREG', talib.LINEARREG(df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('LINEARREG_ANGLE', talib.LINEARREG_ANGLE(df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('LINEARREG_INTERCEPT', talib.LINEARREG_INTERCEPT(df['close'])))\n",
    "    indicator_columns.append(\n",
    "        ('LINEARREG_SLOPE', talib.LINEARREG_SLOPE(df['close'])))\n",
    "    # new_columns['STDDEV'] = df['close'].rolling(timeperiod).std()\n",
    "    indicator_columns.append(('TSF', talib.TSF(df['close'])))\n",
    "    indicator_columns.append(('VAR', talib.VAR(df['close'])))\n",
    "    # Iterate over the time periods\n",
    "    for timeperiod in timeperiods:\n",
    "        #########Overlap Studies\n",
    "        indicator_columns.append((f'BB_upper_{timeperiod}',\n",
    "                                  talib.BBANDS(df['close'],\n",
    "                                               timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'BB_middle_{timeperiod}',\n",
    "                                  talib.BBANDS(df['close'],\n",
    "                                               timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'BB_lower_{timeperiod}',\n",
    "                                  talib.BBANDS(df['close'],\n",
    "                                               timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'DEMA_{timeperiod}',\n",
    "                                  talib.DEMA(df['close'],\n",
    "                                             timeperiod=timeperiod)))\n",
    "        indicator_columns.append(\n",
    "            (f'EMA_{timeperiod}', talib.EMA(df['close'],\n",
    "                                            timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'KAMA_{timeperiod}',\n",
    "                                  talib.KAMA(df['close'],\n",
    "                                             timeperiod=timeperiod)))\n",
    "        indicator_columns.append(\n",
    "            (f'MA_{timeperiod}', talib.MA(df['close'], timeperiod=timeperiod)))\n",
    "        # new_columns['MAMA'], new_columns['FAMA'] = talib.MAMA(df['close'], fastlimit=0, slowlimit=0)\n",
    "        # new_columns['MAVP'] = talib.MAVP(df['close'], periods=None, minperiod=2, maxperiod=30, matype=0)\n",
    "        indicator_columns.append((f'MIDPOINT_{timeperiod}',\n",
    "                                  talib.MIDPOINT(df['close'],\n",
    "                                                 timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'MIDPRICE_{timeperiod}',\n",
    "                                  talib.MIDPRICE(df['high'],\n",
    "                                                 df['low'],\n",
    "                                                 timeperiod=timeperiod)))\n",
    "        indicator_columns.append(\n",
    "            (f'SMA_{timeperiod}', talib.SMA(df['close'],\n",
    "                                            timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'TEMA_{timeperiod}',\n",
    "                                  talib.TEMA(df['close'],\n",
    "                                             timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'TRIMA_{timeperiod}',\n",
    "                                  talib.TRIMA(df['close'],\n",
    "                                              timeperiod=timeperiod)))\n",
    "        indicator_columns.append(\n",
    "            (f'WMA_{timeperiod}', talib.WMA(df['close'],\n",
    "                                            timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'ADX_{timeperiod}',\n",
    "                                  talib.ADX(df['high'],\n",
    "                                            df['low'],\n",
    "                                            df['close'],\n",
    "                                            timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'ADXR_{timeperiod}',\n",
    "                                  talib.ADXR(df['high'],\n",
    "                                             df['low'],\n",
    "                                             df['close'],\n",
    "                                             timeperiod=timeperiod)))\n",
    "        aroon_up, aroon_down = talib.AROON(df['high'],\n",
    "                                           df['low'],\n",
    "                                           timeperiod=timeperiod)\n",
    "        indicator_columns.append((f'AROON_up_{timeperiod}', aroon_up))\n",
    "        indicator_columns.append((f'AROON_down_{timeperiod}', aroon_down))\n",
    "        indicator_columns.append((f'AROONOSC_{timeperiod}',\n",
    "                                  talib.AROONOSC(df['high'],\n",
    "                                                 df['low'],\n",
    "                                                 timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'CCI_{timeperiod}',\n",
    "                                  talib.CCI(df['high'],\n",
    "                                            df['low'],\n",
    "                                            df['close'],\n",
    "                                            timeperiod=timeperiod)))\n",
    "        indicator_columns.append(\n",
    "            (f'CMO_{timeperiod}', talib.CMO(df['close'],\n",
    "                                            timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'DX_{timeperiod}',\n",
    "                                  talib.DX(df['high'],\n",
    "                                           df['low'],\n",
    "                                           df['close'],\n",
    "                                           timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'MFI_{timeperiod}',\n",
    "                                  talib.MFI(df['high'],\n",
    "                                            df['low'],\n",
    "                                            df['close'],\n",
    "                                            df['volume'],\n",
    "                                            timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'MINUS_DI_{timeperiod}',\n",
    "                                  talib.MINUS_DI(df['high'],\n",
    "                                                 df['low'],\n",
    "                                                 df['close'],\n",
    "                                                 timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'MINUS_DM_{timeperiod}',\n",
    "                                  talib.MINUS_DM(df['high'],\n",
    "                                                 df['low'],\n",
    "                                                 timeperiod=timeperiod)))\n",
    "        indicator_columns.append(\n",
    "            (f'MOM_{timeperiod}', talib.MOM(df['close'],\n",
    "                                            timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'PLUS_DI_{timeperiod}',\n",
    "                                  talib.PLUS_DI(df['high'],\n",
    "                                                df['low'],\n",
    "                                                df['close'],\n",
    "                                                timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'PLUS_DM_{timeperiod}',\n",
    "                                  talib.PLUS_DM(df['high'],\n",
    "                                                df['low'],\n",
    "                                                timeperiod=timeperiod)))\n",
    "        indicator_columns.append(\n",
    "            (f'ROC_{timeperiod}', talib.ROC(df['close'],\n",
    "                                            timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'ROCP_{timeperiod}',\n",
    "                                  talib.ROCP(df['close'],\n",
    "                                             timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'ROCR_{timeperiod}',\n",
    "                                  talib.ROCR(df['close'],\n",
    "                                             timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'ROCR100_{timeperiod}',\n",
    "                                  talib.ROCR100(df['close'],\n",
    "                                                timeperiod=timeperiod)))\n",
    "        indicator_columns.append(\n",
    "            (f'RSI_{timeperiod}', talib.RSI(df['close'],\n",
    "                                            timeperiod=timeperiod)))\n",
    "\n",
    "        indicator_columns.append((f'ATR_{timeperiod}',\n",
    "                                  talib.ATR(df['high'],\n",
    "                                            df['low'],\n",
    "                                            df['close'],\n",
    "                                            timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'NATR_{timeperiod}',\n",
    "                                  talib.NATR(df['high'],\n",
    "                                             df['low'],\n",
    "                                             df['close'],\n",
    "                                             timeperiod=timeperiod)))\n",
    "        #########Statistic Functions\n",
    "        indicator_columns.append((f'BETA_{timeperiod}',\n",
    "                                  talib.BETA(df['high'],\n",
    "                                             df['low'],\n",
    "                                             timeperiod=timeperiod)))\n",
    "        indicator_columns.append((f'CORREL_{timeperiod}',\n",
    "                                  talib.CORREL(df['high'],\n",
    "                                               df['low'],\n",
    "                                               timeperiod=timeperiod)))\n",
    "    new_columns = pd.concat([\n",
    "        pd.DataFrame(data, columns=[name]) for name, data in indicator_columns\n",
    "    ],\n",
    "                            axis=1)\n",
    "    return new_columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
