{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f589a10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T08:40:51.878238Z",
     "start_time": "2023-01-27T08:40:51.869234Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from creating_arrays import CHART_TIME_ARRAY, MONTH_ARRAY, SYMBOL_ARRAY\n",
    "from constants import download_dir, output_dir, root_dir, dtypes, BINANCE_DAILY_URL, BINANCE_MONTHLY_URL\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from selenium import webdriver\n",
    "import talib\n",
    "import datetime\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import glob\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import inspect\n",
    "import talib\n",
    "import time\n",
    "import numpy as np\n",
    "import requests\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d161a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T08:43:05.318194Z",
     "start_time": "2023-01-27T08:43:05.308198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01\n"
     ]
    }
   ],
   "source": [
    "# Get the current date\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Format the date as a string in the desired format\n",
    "date_string = now.strftime(\"%Y-%m\")\n",
    "\n",
    "# Print the date string\n",
    "print(date_string)\n",
    "\n",
    "idx = MONTH_ARRAY.index(date_string)\n",
    "MONTH_ARRAY = MONTH_ARRAY[:idx + 1]\n",
    "# months = MONTH_ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b53ac8e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T08:43:05.550025Z",
     "start_time": "2023-01-27T08:43:05.534011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08', '2023-01-09', '2023-01-10', '2023-01-11', '2023-01-12', '2023-01-13', '2023-01-14', '2023-01-15', '2023-01-16', '2023-01-17', '2023-01-18', '2023-01-19', '2023-01-20', '2023-01-21', '2023-01-22', '2023-01-23', '2023-01-24', '2023-01-25', '2023-01-26', '2023-01-27']\n"
     ]
    }
   ],
   "source": [
    "# Get the current date\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Get the first day of the current month\n",
    "first_day = now.replace(day=1)\n",
    "\n",
    "# Create an empty list to store the days\n",
    "DAY_ARRAY = []\n",
    "\n",
    "# Loop through the days from the first day of the current month to today\n",
    "while first_day <= now:\n",
    "    # Format the date as a string in the desired format\n",
    "    date_string = first_day.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Add the date string to the list\n",
    "    DAY_ARRAY.append(date_string)\n",
    "\n",
    "    # Move to the next day\n",
    "    first_day += datetime.timedelta(days=1)\n",
    "print(DAY_ARRAY)\n",
    "# days = DAY_ARRAY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad9cbb8",
   "metadata": {},
   "source": [
    "## Set up the arrays of symbols, chart times, and months to narrow it down to exactly what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27bbaee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T09:13:55.029750Z",
     "start_time": "2023-01-27T09:13:55.019748Z"
    }
   },
   "outputs": [],
   "source": [
    "master_dictionary = {\n",
    "    \"days\" : DAY_ARRAY,\n",
    "    \"months\" : MONTH_ARRAY,\n",
    "    \"symbols\" : [\n",
    "    SYMBOL_ARRAY[SYMBOL_ARRAY.index('BTCUSDT')],\n",
    "    #     SYMBOL_ARRAY[SYMBOL_ARRAY.index('ETHUSDT')],\n",
    "    #     SYMBOL_ARRAY[SYMBOL_ARRAY.index('ETHBUSD')],\n",
    "    #     SYMBOL_ARRAY[SYMBOL_ARRAY.index('BTCBUSD')]\n",
    "    ],\n",
    "    \"chart_times\" : [\n",
    "#     CHART_TIME_ARRAY[CHART_TIME_ARRAY.index('5m')],\n",
    "#     CHART_TIME_ARRAY[CHART_TIME_ARRAY.index('1m')],\n",
    "    CHART_TIME_ARRAY[CHART_TIME_ARRAY.index('15m')]\n",
    "],\n",
    "    \"timeperiods\" : [5, 8, 13, 21, 30, 34, 50, 55, 89, 100, 144, 200, 233]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4834e69c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T08:43:08.523820Z",
     "start_time": "2023-01-27T08:43:08.512816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01\n",
      "2023-01-02\n",
      "2023-01-03\n",
      "2023-01-04\n",
      "2023-01-05\n",
      "2023-01-06\n",
      "2023-01-07\n",
      "2023-01-08\n",
      "2023-01-09\n",
      "2023-01-10\n",
      "2023-01-11\n",
      "2023-01-12\n",
      "2023-01-13\n",
      "2023-01-14\n",
      "2023-01-15\n",
      "2023-01-16\n",
      "2023-01-17\n",
      "2023-01-18\n",
      "2023-01-19\n",
      "2023-01-20\n",
      "2023-01-21\n",
      "2023-01-22\n",
      "2023-01-23\n",
      "2023-01-24\n",
      "2023-01-25\n",
      "2023-01-26\n",
      "2023-01-27\n"
     ]
    }
   ],
   "source": [
    "for i in master_dictionary[\"days\"]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aee831",
   "metadata": {},
   "source": [
    "## Download the monthly data and move to separate folders for each symbol_charttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e73aa782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T08:49:35.319825Z",
     "start_time": "2023-01-27T08:49:35.299810Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_data(master_dictionary, monthly_or_daily_1_2):\n",
    "    if monthly_or_daily_1_2 == \"m\" or monthly_or_daily_1_2 == \"M\" or monthly_or_daily_1_2 == \"monthly\" or monthly_or_daily_1_2 == 1:\n",
    "        for symbol in master_dictionary[\"symbols\"]:\n",
    "            for chart_time in master_dictionary[\"chart_times\"]:\n",
    "                for month in master_dictionary[\"months\"]:\n",
    "                    # Construct the link\n",
    "                    link = f\"{BINANCE_MONTHLY_URL}{symbol}/{chart_time}/{symbol}-{chart_time}-{month}.zip\"\n",
    "                    # Create the file path\n",
    "                    file_path = Path(download_dir) / f\"{symbol}-{chart_time}-{month}.zip\"\n",
    "                    try:\n",
    "                        # Download the file\n",
    "                        urllib.request.urlretrieve(link, f\"{symbol}-{chart_time}-{month}.zip\")\n",
    "        #                 print(f'{file_path} downloaded successfully')\n",
    "                    except:\n",
    "                        print(f'{file_path} not found')\n",
    "                        continue\n",
    "        for symbol in master_dictionary[\"symbols\"]:\n",
    "            for chart_time in master_dictionary[\"chart_times\"]:\n",
    "                # Create the new folder path\n",
    "                new_folder_path = Path(download_dir) / f\"{symbol}-{chart_time}-monthly_data\"\n",
    "                new_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "                # match pattern of the file\n",
    "                pattern = re.compile(f\"^{symbol}-{chart_time}-\\d{{4}}-\\d{{2}}\\.zip$\")\n",
    "                # list all files in the download directory\n",
    "                files = os.listdir(root_dir)\n",
    "                for file in files:\n",
    "                    if pattern.match(file):\n",
    "                        src = Path(root_dir) / file\n",
    "                        dst = new_folder_path / file\n",
    "                        src.rename(dst)\n",
    "    if monthly_or_daily_1_2 == \"d\" or monthly_or_daily_1_2 == \"D\" or monthly_or_daily_1_2 == \"daily\" or monthly_or_daily_1_2 == 2:\n",
    "        for symbol in master_dictionary[\"symbols\"]:\n",
    "            for chart_time in master_dictionary[\"chart_times\"]:\n",
    "                for day in master_dictionary[\"days\"]:\n",
    "                    # Construct the link\n",
    "                    link = f\"{BINANCE_DAILY_URL}{symbol}/{chart_time}/{symbol}-{chart_time}-{day}.zip\"\n",
    "                    # Create the file path\n",
    "                    file_path = Path(download_dir) / f\"{symbol}-{chart_time}-{day}.zip\"\n",
    "                    try:\n",
    "                        # Download the file\n",
    "                        urllib.request.urlretrieve(link, f\"{symbol}-{chart_time}-{day}.zip\")\n",
    "                        # print(f'{file_path} downloaded successfully')\n",
    "                    except:\n",
    "                        print(f'{file_path} not found')\n",
    "                        continue\n",
    "        for symbol in master_dictionary[\"symbols\"]:\n",
    "            for chart_time in master_dictionary[\"chart_times\"]:\n",
    "                # Create the new folder path\n",
    "                new_folder_path = Path(download_dir) / f\"{symbol}-{chart_time}-daily_data\"\n",
    "                new_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "                # match pattern of the file\n",
    "                pattern = re.compile(f\"^{symbol}-{chart_time}-\\d{{4}}-\\d{{2}}-\\d{{2}}\\.zip$\")\n",
    "                # list all files in the download directory\n",
    "                files = os.listdir(root_dir)\n",
    "                for file in files:\n",
    "                    if pattern.match(file):\n",
    "                        src = Path(root_dir) / file\n",
    "                        dst = new_folder_path / file\n",
    "                        if dst.exists():\n",
    "                            dst.unlink()\n",
    "                        src.rename(dst)\n",
    "    return(\"data downloaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78e3d506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T08:53:35.931831Z",
     "start_time": "2023-01-27T08:52:41.060454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\KISHORE\\Binance-Data-Downloader\\downloaded_data\\BTCUSDT-15m-2023-01.zip not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data downloaded'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_data(master_dictionary=master_dictionary, monthly_or_daily_1_2=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76591e2",
   "metadata": {},
   "source": [
    "## Unzip the Zip files and concatenate the CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed631cb",
   "metadata": {},
   "source": [
    "### Move the monthly zips and csvs to a new folder.\n",
    "#### Earlier, I wanted to delete them completely. But then I realized binance will not give more than 24 months of data at a time so now that we're in 2023, we wont get 2020 data. So I have decided not to delete those. (okay im not sure about this but i still dont want to risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5dfb843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T08:56:24.031707Z",
     "start_time": "2023-01-27T08:56:24.011702Z"
    }
   },
   "outputs": [],
   "source": [
    "def unzip_and_concatenate_csv(master_dictionary, monthly_or_daily_1_2):\n",
    "    if monthly_or_daily_1_2 == \"m\" or monthly_or_daily_1_2 == \"M\" or monthly_or_daily_1_2 == \"monthly\" or monthly_or_daily_1_2 == 1:\n",
    "        for symbol in master_dictionary[\"symbols\"]:\n",
    "            for chart_time in master_dictionary[\"chart_times\"]:\n",
    "                # Set up an empty list for the data frames\n",
    "                df_list = []\n",
    "\n",
    "                # Compile the regular expression pattern\n",
    "                pattern = re.compile(f\"^{symbol}-{chart_time}-\\d{{4}}-\\d{{2}}\\.zip$\")\n",
    "\n",
    "                # Create the new folder path for ZIP files\n",
    "                new_zip_folder_path = os.path.join(download_dir,\n",
    "                                                   f\"{symbol}-{chart_time}-monthly_data\")\n",
    "\n",
    "                # Create the new folder path for CSV files\n",
    "                new_csv_folder_path = os.path.join(output_dir,\n",
    "                                                   f\"{symbol}-{chart_time}-monthly_data\")\n",
    "\n",
    "                # Iterate over the files in the new zip folder\n",
    "                for file in os.listdir(new_zip_folder_path):\n",
    "                    # Check if the file matches the pattern\n",
    "                    if pattern.match(file):\n",
    "                        # Construct the file path\n",
    "                        file_path = os.path.join(new_zip_folder_path, file)\n",
    "\n",
    "                        # Extract the ZIP file\n",
    "                        with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                            zip_ref.extractall(new_csv_folder_path)\n",
    "\n",
    "                        # Construct the CSV file path\n",
    "                        csv_file_path = os.path.join(\n",
    "                            new_csv_folder_path,\n",
    "                            f\"{symbol}-{chart_time}{file[-12:-4]}.csv\")\n",
    "\n",
    "                        # Read the CSV file into a data frame, ignoring the headers\n",
    "                        df = pd.read_csv(csv_file_path, header=None)\n",
    "\n",
    "                        # Remove the first row (which contains the header)\n",
    "                        df = df.iloc[1:]\n",
    "\n",
    "                        # Add it to the list\n",
    "                        df_list.append(df)\n",
    "\n",
    "                # Concatenate the data frames in the list\n",
    "                df_final = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "                # Read the headers from the first CSV file\n",
    "                headers = pd.read_csv(csv_file_path, nrows=1).columns\n",
    "\n",
    "                # Set the headers as the column names of the final dataframe\n",
    "                df_final.columns = headers\n",
    "\n",
    "                # Convert 'open_time' and 'close_time' columns to datetime\n",
    "                df_final['open_time'] = pd.to_datetime(\n",
    "                    df_final['open_time'],\n",
    "                    unit='ms').dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "                df_final['close_time'] = pd.to_datetime(\n",
    "                    df_final['close_time'],\n",
    "                    unit='ms').dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "\n",
    "                # Delete the 'ignore' column\n",
    "                df_final = df_final.drop(['ignore'], axis=1)\n",
    "\n",
    "                # Add a new column called 'entry' that will take previous close\n",
    "                df_final['entry'] = df_final['close'].shift(1)\n",
    "                # Set the file name\n",
    "                file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "\n",
    "                # Construct the file path\n",
    "                file_path = os.path.join(new_csv_folder_path, file_name)\n",
    "\n",
    "                # Write the data frame to the Excel file\n",
    "                df_final.to_csv(file_path, index=False)\n",
    "    if monthly_or_daily_1_2 == \"d\" or monthly_or_daily_1_2 == \"D\" or monthly_or_daily_1_2 == \"daily\" or monthly_or_daily_1_2 == 2:\n",
    "        for symbol in master_dictionary[\"symbols\"]:\n",
    "            for chart_time in master_dictionary[\"chart_times\"]:\n",
    "                # Set up an empty list for the data frames\n",
    "                df_list = []\n",
    "\n",
    "                # Compile the regular expression pattern for daily zip files\n",
    "                pattern = re.compile(f\"^{symbol}-{chart_time}-\\d{{4}}-\\d{{2}}-\\d{{2}}\\.zip$\")\n",
    "\n",
    "                # Create the new folder path for daily ZIP files\n",
    "                new_daily_zip_folder_path = os.path.join(download_dir, f\"{symbol}-{chart_time}-daily_data\")\n",
    "\n",
    "                if not os.path.exists(new_daily_zip_folder_path):\n",
    "                    os.mkdir(new_daily_zip_folder_path)\n",
    "\n",
    "                # Create the new folder path for daily CSV files\n",
    "                new_daily_csv_folder_path = os.path.join(output_dir, f\"{symbol}-{chart_time}-daily_data\")\n",
    "\n",
    "                if not os.path.exists(new_daily_csv_folder_path):\n",
    "                    os.mkdir(new_daily_csv_folder_path)\n",
    "\n",
    "                # Iterate over the files in the new daily zip folder\n",
    "                for file in os.listdir(new_daily_zip_folder_path):\n",
    "                    # Check if the file matches the pattern\n",
    "                    if pattern.match(file):\n",
    "                        # Construct the file path\n",
    "                        file_path = os.path.join(new_daily_zip_folder_path, file)\n",
    "\n",
    "                        # Extract the ZIP file\n",
    "                        with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "\n",
    "                            # Construct the CSV file path\n",
    "                            csv_file_path = os.path.join(new_daily_csv_folder_path, f\"{symbol}-{chart_time}-{file.split('-')[-3]}-{file.split('-')[-2]}-{file.split('-')[-1][:-4]}.csv\")\n",
    "\n",
    "                            # Check if the extracted csv already exists, and if so, delete it\n",
    "                            if os.path.exists(csv_file_path):\n",
    "                                os.remove(csv_file_path)\n",
    "\n",
    "                            zip_ref.extractall(new_daily_csv_folder_path)\n",
    "\n",
    "                        # Read the CSV file into a data frame, ignoring the headers\n",
    "                        df = pd.read_csv(csv_file_path, header=None)\n",
    "\n",
    "                        # Remove the first row (which contains the header)\n",
    "                        df = df.iloc[1:]\n",
    "\n",
    "                        # Add it to the list\n",
    "                        df_list.append(df)\n",
    "\n",
    "                # Concatenate the data frames in the list\n",
    "                df_final = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "                # Read the headers from the first CSV file\n",
    "                headers = pd.read_csv(csv_file_path, nrows=1).columns\n",
    "\n",
    "                # Set the headers as the column names of the final dataframe\n",
    "                df_final.columns = headers\n",
    "\n",
    "                # Convert 'open_time' and 'close_time' columns to datetime\n",
    "                df_final['open_time'] = pd.to_datetime(df_final['open_time'], unit='ms').dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "                df_final['close_time'] = pd.to_datetime(df_final['close_time'], unit='ms').dt.tz_localize('UTC').dt.tz_convert('Asia/Kolkata')\n",
    "\n",
    "                # Delete the 'ignore' column\n",
    "                df_final = df_final.drop(['ignore'], axis=1)\n",
    "\n",
    "                # Add a new column called 'entry' that will take previous close\n",
    "                df_final['entry'] = df_final['close'].shift(1)\n",
    "\n",
    "                # Set the file name\n",
    "                file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "\n",
    "                # Construct the file path\n",
    "                file_path = os.path.join(new_daily_csv_folder_path, file_name)\n",
    "\n",
    "                # Check if the file already exists and remove it\n",
    "                if os.path.exists(file_path):\n",
    "                    os.remove(file_path)\n",
    "\n",
    "                # Write the data frame to the Excel file\n",
    "                df_final.to_csv(file_path, index=False)\n",
    "    return(\"csvs have been concatenated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ef52439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T08:56:27.811891Z",
     "start_time": "2023-01-27T08:56:24.641807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'csvs have been concatenated'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unzip_and_concatenate_csv(master_dictionary, monthly_or_daily_1_2=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1886e2d8",
   "metadata": {},
   "source": [
    "## Calculate for monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cd603c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T08:59:46.895327Z",
     "start_time": "2023-01-27T08:59:46.877323Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_wins_losses(master_dictionary, monthly_or_daily_1_2, win_perc = 0.5, loss_perc = 0.4):\n",
    "    for symbol in master_dictionary[\"symbols\"]:\n",
    "        for chart_time in master_dictionary[\"chart_times\"]:\n",
    "            # Construct the file name\n",
    "            file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "            if monthly_or_daily_1_2 == \"m\" or monthly_or_daily_1_2 == \"M\" or monthly_or_daily_1_2 == \"monthly\" or monthly_or_daily_1_2 == 1:\n",
    "                # Construct the file path\n",
    "                file_path = Path(output_dir) / f\"{symbol}-{chart_time}-monthly_data/{file_name}\"\n",
    "            if monthly_or_daily_1_2 == \"d\" or monthly_or_daily_1_2 == \"D\" or monthly_or_daily_1_2 == \"daily\" or monthly_or_daily_1_2 == 2:\n",
    "                file_path = Path(output_dir) / f\"{symbol}-{chart_time}-daily_data/{file_name}\"\n",
    "            # Read the CSV file into a dataframe\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"if_short\"] = 0\n",
    "            df[\"if_long\"] = 0\n",
    "            df[\"long_target\"] = np.nan\n",
    "            df[\"short_target\"] = np.nan\n",
    "            df[\"long_stop_loss\"] = np.nan\n",
    "            df[\"short_stop_loss\"] = np.nan\n",
    "            df[\"shorts_win_after\"] = np.nan\n",
    "            df[\"longs_win_after\"] = np.nan\n",
    "            df[\"dual_loss\"] = 0\n",
    "            df[\"entered_before\"] = np.nan\n",
    "\n",
    "            for i in range(len(df)):\n",
    "                if df[\"entry\"][i]:\n",
    "                    long_target = df[\"entry\"][i] * (1 + win_perc / 100)\n",
    "                    short_target = df[\"entry\"][i] * (1 - win_perc / 100)\n",
    "                    long_stop_loss = df[\"entry\"][i] * (1 - loss_perc / 100)\n",
    "                    short_stop_loss = df[\"entry\"][i] * (1 + loss_perc / 100)\n",
    "                    df.loc[i, 'long_target'] = long_target\n",
    "                    df.loc[i, 'long_stop_loss'] = long_stop_loss\n",
    "                    for j in range(i, len(df)):\n",
    "                        if df[\"high\"][j] >= long_target:\n",
    "                            if df[\"low\"][j] <= long_stop_loss:\n",
    "                                df.loc[i, 'if_long'] = -1\n",
    "                                df.loc[i, 'dual_loss'] = 1\n",
    "                                df.loc[i, 'entered_before'] = j - i\n",
    "                            else:\n",
    "                                df.loc[i, 'if_long'] = 1\n",
    "                                df.loc[i, 'longs_win_after'] = j - i\n",
    "                            break\n",
    "                        elif df[\"low\"][j] <= long_stop_loss:\n",
    "                            df.loc[i, 'if_long'] = -1\n",
    "                            break\n",
    "                    df.loc[i, 'short_target'] = short_target\n",
    "                    df.loc[i, 'short_stop_loss'] = short_stop_loss\n",
    "                    for j in range(i, len(df)):\n",
    "                        if df[\"low\"][j] <= short_target:\n",
    "                            if df[\"high\"][j] >= short_stop_loss:\n",
    "                                df.loc[i, 'if_short'] = -1\n",
    "                                df.loc[i, 'dual_loss'] = 1\n",
    "                                df.loc[i, 'entered_before'] = j - i\n",
    "                            else:\n",
    "                                df.loc[i, 'if_short'] = 1\n",
    "                                df.loc[i, 'shorts_win_after'] = j - i\n",
    "                            break\n",
    "                        elif df[\"high\"][j] >= short_stop_loss:\n",
    "                            df.loc[i, 'if_short'] = -1\n",
    "                            break\n",
    "            # Save the updated dataframe to the CSV file\n",
    "            df.to_csv(file_path, index=False)\n",
    "    return(\"calculated wins and losses \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58a85c39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T09:11:54.423633Z",
     "start_time": "2023-01-27T09:11:54.292606Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_indicator_values_old(master_dictionary, monthly_or_daily_1_2):\n",
    "    # Iterate over the symbols and chart times\n",
    "    for symbol in symbols:\n",
    "        for chart_time in chart_times:\n",
    "            # Construct the file name\n",
    "            file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "            if monthly_or_daily_1_2 == \"m\" or monthly_or_daily_1_2 == \"M\" or monthly_or_daily_1_2 == \"monthly\" or monthly_or_daily_1_2 == 1:\n",
    "                # Construct the file path\n",
    "                file_path = Path(output_dir) / f\"{symbol}-{chart_time}-monthly_data/{file_name}\"\n",
    "            elif monthly_or_daily_1_2 == \"d\" or monthly_or_daily_1_2 == \"D\" or monthly_or_daily_1_2 == \"daily\" or monthly_or_daily_1_2 == 2:\n",
    "                # Construct the file path\n",
    "                file_path = Path(output_dir) / f\"{symbol}-{chart_time}-daily_data/{file_name}\"\n",
    "            # Read the CSV file into a dataframe\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(df.dtypes)\n",
    "            #########Overlap Studies\n",
    "            df['BB_upper'], df['BB_middle'], df['BB_lower'] = talib.BBANDS(df['close'], timeperiod=5)\n",
    "            df['DEMA'] = talib.DEMA(df['close'], timeperiod=30)\n",
    "            df['EMA-50'] = talib.EMA(df['close'], timeperiod=50)\n",
    "            df['EMA-200'] = talib.EMA(df['close'], timeperiod=200)\n",
    "            df['HT_TRENDLINE'] = talib.HT_TRENDLINE(df['close'])\n",
    "            df['KAMA'] = talib.KAMA(df['close'], timeperiod=30)\n",
    "            df['MA'] = talib.MA(df['close'], timeperiod=14)\n",
    "    #         df['MAMA'], df['FAMA'] = talib.MAMA(df['close'], fastlimit=0, slowlimit=0)\n",
    "    #         df['MAVP'] = talib.MAVP(df['close'], periods=None, minperiod=2, maxperiod=30, matype=0)\n",
    "            df['MIDPOINT'] = talib.MIDPOINT(df['close'], timeperiod=14)\n",
    "            df['MIDPRICE'] = talib.MIDPRICE(df['high'], df['low'], timeperiod=14)\n",
    "            df['SAR'] = talib.SAR(df['high'], df['low'], acceleration=0, maximum=0)\n",
    "            df['SAREXT'] = talib.SAREXT(df['high'], df['low'])\n",
    "            df['SMA'] = talib.SMA(df['close'], timeperiod=14)\n",
    "            df['T3'] = talib.T3(df['close'], timeperiod=5, vfactor=0)\n",
    "            df['TEMA'] = talib.TEMA(df['close'])\n",
    "            df['TRIMA'] = talib.TRIMA(df['close'])\n",
    "            df['WMA'] = talib.WMA(df['close'])\n",
    "            #########Momentum Indicators\n",
    "            df['ADX'] = talib.ADX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "            df['ADXR'] = talib.ADXR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "            df['APO'] = talib.APO(df['close'], fastperiod=12, slowperiod=26)\n",
    "            df['AROON_up'], df['AROON_down'] = talib.AROON(df['high'], df['low'], timeperiod=14)\n",
    "            df['AROONOSC'] = talib.AROONOSC(df['high'], df['low'], timeperiod=14)\n",
    "            df['BOP'] = talib.BOP(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CCI'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "            df['CMO'] = talib.CMO(df['close'], timeperiod=14)\n",
    "            df['DX'] = talib.DX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "            df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            df['MFI'] = talib.MFI(df['high'], df['low'], df['close'], df['volume'], timeperiod=14)\n",
    "            df['MINUS_DI'] = talib.MINUS_DI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "            df['MINUS_DM'] = talib.MINUS_DM(df['high'], df['low'], timeperiod=14)\n",
    "            df['MOM'] = talib.MOM(df['close'], timeperiod=14)\n",
    "            df['PLUS_DI'] = talib.PLUS_DI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "            df['PLUS_DM'] = talib.PLUS_DM(df['high'], df['low'], timeperiod=14)\n",
    "            df['PPO'] = talib.PPO(df['close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "            df['ROC'] = talib.ROC(df['close'], timeperiod=14)\n",
    "            df['ROCP'] = talib.ROCP(df['close'], timeperiod=14)\n",
    "            df['ROCR'] = talib.ROCR(df['close'], timeperiod=14)\n",
    "            df['ROCR100'] = talib.ROCR100(df['close'], timeperiod=14)\n",
    "            df['RSI'] = talib.RSI(df['close'], timeperiod=8)\n",
    "            df['TRIX'] = talib.TRIX(df['close'])\n",
    "            df['ULTOSC'] = talib.ULTOSC(df['high'], df['low'], df['close'])\n",
    "            df['WILLR'] = talib.WILLR(df['high'], df['low'], df['close'])\n",
    "\n",
    "            #Not Working ATM\n",
    "    #         df['STOCH'] = talib.STOCH(df['high'], df['low'], df['close'])\n",
    "    #         df['STOCHF'] = talib.STOCHF(df['high'], df['low'], df['close'])\n",
    "    #         df['STOCHRSI'] = talib.STOCHRSI(df['close'])\n",
    "    #         df['MACDEXT'] = talib.MACDEXT(df['close'], fastperiod=12, fastmatype=0, slowperiod=26, slowmatype=0, signalperiod=9, signalmatype=0)\n",
    "    #         df['MACDFIX'] = talib.MACDFIX(df['close'], signalperiod=9)\n",
    "            #########Volume Indicators\n",
    "            df['AD'] = talib.AD(df['high'], df['low'], df['close'], df['volume'])\n",
    "            df['ADOSC'] = talib.ADOSC(df['high'], df['low'], df['close'], df['volume'], fastperiod=3, slowperiod=10)\n",
    "            df['OBV'] = talib.OBV(df['close'], df['volume'])\n",
    "            #########Cycle Indicators\n",
    "            df['HT_DCPERIOD'] = talib.HT_DCPERIOD(df['close'])\n",
    "            df['HT_DCPHASE'] = talib.HT_DCPHASE(df['close'])\n",
    "            df['HT_PHASOR_inphase'], df['HT_PHASOR_quadrature'] = talib.HT_PHASOR(df['close'])\n",
    "    #         df['HT_SINE'] = talib.HT_SINE(df['close'])\n",
    "            df['HT_TRENDMODE'] = talib.HT_TRENDMODE(df['close'])\n",
    "            #########Price Transform\n",
    "            df['AVGPRICE'] = talib.AVGPRICE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['MEDPRICE'] = talib.MEDPRICE(df['high'], df['low'])\n",
    "            df['TYPPRICE'] = talib.TYPPRICE(df['high'], df['low'], df['close'])\n",
    "            df['WCLPRICE'] = talib.WCLPRICE(df['high'], df['low'], df['close'])\n",
    "            #########Volatility Indicators\n",
    "            df['ATR'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "            df['NATR'] = talib.NATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "            df['TRANGE'] = talib.TRANGE(df['high'], df['low'], df['close'])\n",
    "            #########Pattern Recognition\n",
    "            df['CDL2CROWS'] = talib.CDL2CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3BLACKCROWS'] = talib.CDL3BLACKCROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3INSIDE'] = talib.CDL3INSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3LINESTRIKE'] = talib.CDL3LINESTRIKE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3OUTSIDE'] = talib.CDL3OUTSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3STARSINSOUTH'] = talib.CDL3STARSINSOUTH(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3WHITESOLDIERS'] = talib.CDL3WHITESOLDIERS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLABANDONEDBABY'] = talib.CDLABANDONEDBABY(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            df['CDLADVANCEBLOCK'] = talib.CDLADVANCEBLOCK(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLBELTHOLD'] = talib.CDLBELTHOLD(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLBREAKAWAY'] = talib.CDLBREAKAWAY(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLCLOSINGMARUBOZU'] = talib.CDLCLOSINGMARUBOZU(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLCONCEALBABYSWALL'] = talib.CDLCONCEALBABYSWALL(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLCOUNTERATTACK'] = talib.CDLCOUNTERATTACK(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLDARKCLOUDCOVER'] = talib.CDLDARKCLOUDCOVER(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            df['CDLDOJI'] = talib.CDLDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLDOJISTAR'] = talib.CDLDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLDRAGONFLYDOJI'] = talib.CDLDRAGONFLYDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLENGULFING'] = talib.CDLENGULFING(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLEVENINGDOJISTAR'] = talib.CDLEVENINGDOJISTAR(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            df['CDLEVENINGSTAR'] = talib.CDLEVENINGSTAR(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            df['CDLGAPSIDESIDEWHITE'] = talib.CDLGAPSIDESIDEWHITE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLGRAVESTONEDOJI'] = talib.CDLGRAVESTONEDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHAMMER'] = talib.CDLHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHANGINGMAN'] = talib.CDLHANGINGMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHARAMI'] = talib.CDLHARAMI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHARAMICROSS'] = talib.CDLHARAMICROSS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHIGHWAVE'] = talib.CDLHIGHWAVE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHIKKAKE'] = talib.CDLHIKKAKE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHIKKAKEMOD'] = talib.CDLHIKKAKEMOD(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHOMINGPIGEON'] = talib.CDLHOMINGPIGEON(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLIDENTICAL3CROWS'] = talib.CDLIDENTICAL3CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLINNECK'] = talib.CDLINNECK(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLINVERTEDHAMMER'] = talib.CDLINVERTEDHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLKICKING'] = talib.CDLKICKING(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLKICKINGBYLENGTH'] = talib.CDLKICKINGBYLENGTH(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLLADDERBOTTOM'] = talib.CDLLADDERBOTTOM(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLLONGLEGGEDDOJI'] = talib.CDLLONGLEGGEDDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLLONGLINE'] = talib.CDLLONGLINE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLMARUBOZU'] = talib.CDLMARUBOZU(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLMATCHINGLOW'] = talib.CDLMATCHINGLOW(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLMATHOLD'] = talib.CDLMATHOLD(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            df['CDLMORNINGDOJISTAR'] = talib.CDLMORNINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLMORNINGSTAR'] = talib.CDLMORNINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLONNECK'] = talib.CDLONNECK(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLPIERCING'] = talib.CDLPIERCING(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLRICKSHAWMAN'] = talib.CDLRICKSHAWMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLRISEFALL3METHODS'] = talib.CDLRISEFALL3METHODS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSEPARATINGLINES'] = talib.CDLSEPARATINGLINES(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSHOOTINGSTAR'] = talib.CDLSHOOTINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSHORTLINE'] = talib.CDLSHORTLINE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSPINNINGTOP'] = talib.CDLSPINNINGTOP(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSTALLEDPATTERN'] = talib.CDLSTALLEDPATTERN(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSTICKSANDWICH'] = talib.CDLSTICKSANDWICH(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLTAKURI'] = talib.CDLTAKURI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLTASUKIGAP'] = talib.CDLTASUKIGAP(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLTHRUSTING'] = talib.CDLTHRUSTING(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLTRISTAR'] = talib.CDLTRISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLUNIQUE3RIVER'] = talib.CDLUNIQUE3RIVER(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLUPSIDEGAP2CROWS'] = talib.CDLUPSIDEGAP2CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLXSIDEGAP3METHODS'] = talib.CDLXSIDEGAP3METHODS(df['open'], df['high'], df['low'], df['close'])\n",
    "            #########Statistic Functions\n",
    "            df['BETA'] = talib.BETA(df['high'], df['low'], timeperiod=5)\n",
    "            df['CORREL'] = talib.CORREL(df['high'], df['low'], timeperiod=30)\n",
    "            df['LINEARREG'] = talib.LINEARREG(df['close'])\n",
    "            df['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(df['close'])\n",
    "            df['LINEARREG_INTERCEPT'] = talib.LINEARREG_INTERCEPT(df['close'])\n",
    "            df['LINEARREG_SLOPE'] = talib.LINEARREG_SLOPE(df['close'])\n",
    "    #         df['STDDEV'] = df['close'].rolling(timeperiod).std()\n",
    "            df['TSF'] = talib.TSF(df['close'])\n",
    "            df['VAR'] = talib.VAR(df['close'])\n",
    "\n",
    "            # Save the updated dataframe to the CSV file\n",
    "            df.to_csv(file_path, index=False)\n",
    "    return(\"indicators are added to the csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a59d89",
   "metadata": {},
   "source": [
    "### Adding indicators to Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f17a67d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T09:15:51.754316Z",
     "start_time": "2023-01-27T09:15:51.705305Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_indicator_values_new(master_dictionary, monthly_or_daily_1_2):\n",
    "    # Iterate over the symbols and chart times\n",
    "    for symbol in symbols:\n",
    "        for chart_time in chart_times:\n",
    "            # Construct the file name\n",
    "            file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "\n",
    "            if monthly_or_daily_1_2 == \"m\" or monthly_or_daily_1_2 == \"M\" or monthly_or_daily_1_2 == \"monthly\" or monthly_or_daily_1_2 == 1:\n",
    "                # Construct the file path\n",
    "                file_path = Path(output_dir) / f\"{symbol}-{chart_time}-monthly_data/{file_name}\"\n",
    "            elif monthly_or_daily_1_2 == \"d\" or monthly_or_daily_1_2 == \"D\" or monthly_or_daily_1_2 == \"daily\" or monthly_or_daily_1_2 == 2:\n",
    "                # Construct the file path\n",
    "                file_path = Path(output_dir) / f\"{symbol}-{chart_time}-daily_data/{file_name}\"\n",
    "\n",
    "            # Read the CSV file into a dataframe\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(df.dtypes)\n",
    "            #########Overlap Studies\n",
    "            df['HT_TRENDLINE'] = talib.HT_TRENDLINE(df['close'])\n",
    "    #         df['MAMA'], df['FAMA'] = talib.MAMA(df['close'], fastlimit=0, slowlimit=0)\n",
    "    #         df['MAVP'] = talib.MAVP(df['close'], periods=None, minperiod=2, maxperiod=30, matype=0)\n",
    "            df['SAR'] = talib.SAR(df['high'], df['low'], acceleration=0, maximum=0)\n",
    "            df['SAREXT'] = talib.SAREXT(df['high'], df['low'])\n",
    "            df['T3'] = talib.T3(df['close'], timeperiod=5, vfactor=0)\n",
    "            #########Momentum Indicators\n",
    "            df['APO'] = talib.APO(df['close'], fastperiod=12, slowperiod=26)\n",
    "            df['BOP'] = talib.BOP(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            df['PPO'] = talib.PPO(df['close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "            df['TRIX'] = talib.TRIX(df['close'])\n",
    "            df['ULTOSC'] = talib.ULTOSC(df['high'], df['low'], df['close'])\n",
    "            df['WILLR'] = talib.WILLR(df['high'], df['low'], df['close'])\n",
    "\n",
    "            #Not Working ATM\n",
    "    #         df['STOCH'] = talib.STOCH(df['high'], df['low'], df['close'])\n",
    "    #         df['STOCHF'] = talib.STOCHF(df['high'], df['low'], df['close'])\n",
    "    #         df['STOCHRSI'] = talib.STOCHRSI(df['close'])\n",
    "    #         df['MACDEXT'] = talib.MACDEXT(df['close'], fastperiod=12, fastmatype=0, slowperiod=26, slowmatype=0, signalperiod=9, signalmatype=0)\n",
    "    #         df['MACDFIX'] = talib.MACDFIX(df['close'], signalperiod=9)\n",
    "            #########Volume Indicators\n",
    "            df['AD'] = talib.AD(df['high'], df['low'], df['close'], df['volume'])\n",
    "            df['ADOSC'] = talib.ADOSC(df['high'], df['low'], df['close'], df['volume'], fastperiod=3, slowperiod=10)\n",
    "            df['OBV'] = talib.OBV(df['close'], df['volume'])\n",
    "            #########Cycle Indicators\n",
    "            df['HT_DCPERIOD'] = talib.HT_DCPERIOD(df['close'])\n",
    "            df['HT_DCPHASE'] = talib.HT_DCPHASE(df['close'])\n",
    "            df['HT_PHASOR_inphase'], df['HT_PHASOR_quadrature'] = talib.HT_PHASOR(df['close'])\n",
    "    #         df['HT_SINE'] = talib.HT_SINE(df['close'])\n",
    "            df['HT_TRENDMODE'] = talib.HT_TRENDMODE(df['close'])\n",
    "            #########Price Transform\n",
    "            df['AVGPRICE'] = talib.AVGPRICE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['MEDPRICE'] = talib.MEDPRICE(df['high'], df['low'])\n",
    "            df['TYPPRICE'] = talib.TYPPRICE(df['high'], df['low'], df['close'])\n",
    "            df['WCLPRICE'] = talib.WCLPRICE(df['high'], df['low'], df['close'])\n",
    "            #########Volatility Indicators\n",
    "            df['TRANGE'] = talib.TRANGE(df['high'], df['low'], df['close'])\n",
    "            #########Pattern Recognition\n",
    "            df['CDL2CROWS'] = talib.CDL2CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3BLACKCROWS'] = talib.CDL3BLACKCROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3INSIDE'] = talib.CDL3INSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3LINESTRIKE'] = talib.CDL3LINESTRIKE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3OUTSIDE'] = talib.CDL3OUTSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3STARSINSOUTH'] = talib.CDL3STARSINSOUTH(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDL3WHITESOLDIERS'] = talib.CDL3WHITESOLDIERS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLABANDONEDBABY'] = talib.CDLABANDONEDBABY(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            df['CDLADVANCEBLOCK'] = talib.CDLADVANCEBLOCK(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLBELTHOLD'] = talib.CDLBELTHOLD(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLBREAKAWAY'] = talib.CDLBREAKAWAY(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLCLOSINGMARUBOZU'] = talib.CDLCLOSINGMARUBOZU(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLCONCEALBABYSWALL'] = talib.CDLCONCEALBABYSWALL(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLCOUNTERATTACK'] = talib.CDLCOUNTERATTACK(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLDARKCLOUDCOVER'] = talib.CDLDARKCLOUDCOVER(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            df['CDLDOJI'] = talib.CDLDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLDOJISTAR'] = talib.CDLDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLDRAGONFLYDOJI'] = talib.CDLDRAGONFLYDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLENGULFING'] = talib.CDLENGULFING(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLEVENINGDOJISTAR'] = talib.CDLEVENINGDOJISTAR(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            df['CDLEVENINGSTAR'] = talib.CDLEVENINGSTAR(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            df['CDLGAPSIDESIDEWHITE'] = talib.CDLGAPSIDESIDEWHITE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLGRAVESTONEDOJI'] = talib.CDLGRAVESTONEDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHAMMER'] = talib.CDLHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHANGINGMAN'] = talib.CDLHANGINGMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHARAMI'] = talib.CDLHARAMI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHARAMICROSS'] = talib.CDLHARAMICROSS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHIGHWAVE'] = talib.CDLHIGHWAVE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHIKKAKE'] = talib.CDLHIKKAKE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHIKKAKEMOD'] = talib.CDLHIKKAKEMOD(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLHOMINGPIGEON'] = talib.CDLHOMINGPIGEON(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLIDENTICAL3CROWS'] = talib.CDLIDENTICAL3CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLINNECK'] = talib.CDLINNECK(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLINVERTEDHAMMER'] = talib.CDLINVERTEDHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLKICKING'] = talib.CDLKICKING(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLKICKINGBYLENGTH'] = talib.CDLKICKINGBYLENGTH(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLLADDERBOTTOM'] = talib.CDLLADDERBOTTOM(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLLONGLEGGEDDOJI'] = talib.CDLLONGLEGGEDDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLLONGLINE'] = talib.CDLLONGLINE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLMARUBOZU'] = talib.CDLMARUBOZU(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLMATCHINGLOW'] = talib.CDLMATCHINGLOW(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLMATHOLD'] = talib.CDLMATHOLD(df['open'], df['high'], df['low'], df['close'], penetration=0)\n",
    "            df['CDLMORNINGDOJISTAR'] = talib.CDLMORNINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLMORNINGSTAR'] = talib.CDLMORNINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLONNECK'] = talib.CDLONNECK(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLPIERCING'] = talib.CDLPIERCING(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLRICKSHAWMAN'] = talib.CDLRICKSHAWMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLRISEFALL3METHODS'] = talib.CDLRISEFALL3METHODS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSEPARATINGLINES'] = talib.CDLSEPARATINGLINES(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSHOOTINGSTAR'] = talib.CDLSHOOTINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSHORTLINE'] = talib.CDLSHORTLINE(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSPINNINGTOP'] = talib.CDLSPINNINGTOP(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSTALLEDPATTERN'] = talib.CDLSTALLEDPATTERN(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLSTICKSANDWICH'] = talib.CDLSTICKSANDWICH(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLTAKURI'] = talib.CDLTAKURI(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLTASUKIGAP'] = talib.CDLTASUKIGAP(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLTHRUSTING'] = talib.CDLTHRUSTING(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLTRISTAR'] = talib.CDLTRISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLUNIQUE3RIVER'] = talib.CDLUNIQUE3RIVER(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLUPSIDEGAP2CROWS'] = talib.CDLUPSIDEGAP2CROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "            df['CDLXSIDEGAP3METHODS'] = talib.CDLXSIDEGAP3METHODS(df['open'], df['high'], df['low'], df['close'])\n",
    "            #########Statistic Functions\n",
    "            df['LINEARREG'] = talib.LINEARREG(df['close'])\n",
    "            df['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(df['close'])\n",
    "            df['LINEARREG_INTERCEPT'] = talib.LINEARREG_INTERCEPT(df['close'])\n",
    "            df['LINEARREG_SLOPE'] = talib.LINEARREG_SLOPE(df['close'])\n",
    "    #         df['STDDEV'] = df['close'].rolling(timeperiod).std()\n",
    "            df['TSF'] = talib.TSF(df['close'])\n",
    "            df['VAR'] = talib.VAR(df['close'])\n",
    "            # Iterate over the time periods\n",
    "            for timeperiod in master_dictionary[\"timeperiods\"]:\n",
    "\n",
    "                #########Overlap Studies\n",
    "                df[f'BB_upper_{timeperiod}'], df[f'BB_middle_{timeperiod}'], df[f'BB_lower_{timeperiod}'] = talib.BBANDS(df['close'], timeperiod=timeperiod)\n",
    "                df[f'DEMA_{timeperiod}'] = talib.DEMA(df['close'], timeperiod=timeperiod)\n",
    "                df[f'EMA_{timeperiod}'] = talib.EMA(df['close'], timeperiod=timeperiod)\n",
    "                df[f'KAMA_{timeperiod}'] = talib.KAMA(df['close'], timeperiod=timeperiod)\n",
    "                df[f'MA_{timeperiod}'] = talib.MA(df['close'], timeperiod=timeperiod)\n",
    "        #         df['MAMA'], df['FAMA'] = talib.MAMA(df['close'], fastlimit=0, slowlimit=0)\n",
    "        #         df['MAVP'] = talib.MAVP(df['close'], periods=None, minperiod=2, maxperiod=30, matype=0)\n",
    "                df[f'MIDPOINT_{timeperiod}'] = talib.MIDPOINT(df['close'], timeperiod=timeperiod)\n",
    "                df[f'MIDPRICE_{timeperiod}'] = talib.MIDPRICE(df['high'], df['low'], timeperiod=timeperiod)\n",
    "                df[f'SMA_{timeperiod}'] = talib.SMA(df['close'], timeperiod=timeperiod)\n",
    "                df[f'TEMA_{timeperiod}'] = talib.TEMA(df['close'], timeperiod=timeperiod)\n",
    "                df[f'TRIMA_{timeperiod}'] = talib.TRIMA(df['close'], timeperiod=timeperiod)\n",
    "                df[f'WMA_{timeperiod}'] = talib.WMA(df['close'], timeperiod=timeperiod)\n",
    "                df[f'ADX_{timeperiod}'] = talib.ADX(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                df[f'ADXR_{timeperiod}'] = talib.ADXR(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                df[f'AROON_up_{timeperiod}'], df[f'AROON_down_{timeperiod}'] = talib.AROON(df['high'], df['low'], timeperiod=timeperiod)\n",
    "                df[f'AROONOSC_{timeperiod}'] = talib.AROONOSC(df['high'], df['low'], timeperiod=timeperiod)\n",
    "                df[f'CCI_{timeperiod}'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                df[f'CMO_{timeperiod}'] = talib.CMO(df['close'], timeperiod=timeperiod)\n",
    "                df[f'DX_{timeperiod}'] = talib.DX(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                df[f'MFI_{timeperiod}'] = talib.MFI(df['high'], df['low'], df['close'], df['volume'], timeperiod=timeperiod)\n",
    "                df[f'MINUS_DI_{timeperiod}'] = talib.MINUS_DI(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                df[f'MINUS_DM_{timeperiod}'] = talib.MINUS_DM(df['high'], df['low'], timeperiod=timeperiod)\n",
    "                df[f'MOM_{timeperiod}'] = talib.MOM(df['close'], timeperiod=timeperiod)\n",
    "                df[f'PLUS_DI_{timeperiod}'] = talib.PLUS_DI(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                df[f'PLUS_DM_{timeperiod}'] = talib.PLUS_DM(df['high'], df['low'], timeperiod=timeperiod)\n",
    "                df[f'ROC_{timeperiod}'] = talib.ROC(df['close'], timeperiod=timeperiod)\n",
    "                df[f'ROCP_{timeperiod}'] = talib.ROCP(df['close'], timeperiod=timeperiod)\n",
    "                df[f'ROCR_{timeperiod}'] = talib.ROCR(df['close'], timeperiod=timeperiod)\n",
    "                df[f'ROCR100_{timeperiod}'] = talib.ROCR100(df['close'], timeperiod=timeperiod)\n",
    "                df[f'RSI_{timeperiod}'] = talib.RSI(df['close'], timeperiod=timeperiod)\n",
    "\n",
    "                df[f'ATR_{timeperiod}'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                df[f'NATR_{timeperiod}'] = talib.NATR(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n",
    "                #########Statistic Functions\n",
    "                df[f'BETA_{timeperiod}'] = talib.BETA(df['high'], df['low'], timeperiod=timeperiod)\n",
    "                df[f'CORREL_{timeperiod}'] = talib.CORREL(df['high'], df['low'], timeperiod=timeperiod)\n",
    "            # Save the updated dataframe to the CSV file\n",
    "            df.to_csv(file_path, index=False)\n",
    "    return(\"indicators are added to the csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c9a5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-14T05:24:36.430773Z",
     "start_time": "2023-01-14T05:24:36.411769Z"
    }
   },
   "outputs": [],
   "source": [
    "indicators_master_list = talib.get_functions()\n",
    "indicators_list = list(set(indicators_master_list))\n",
    "indicators_list.sort()\n",
    "for indicator in indicators_list:\n",
    "    print(indicator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037296ca",
   "metadata": {},
   "source": [
    "### Troubleshooting utilities. Can be put in another notebook \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = pd.read_csv(csv_file_path, nrows=0).columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165261ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the chart time and symbol\n",
    "chart_time = \"5m\"\n",
    "symbol = \"BTCBUSD\"\n",
    "\n",
    "# Set the file name\n",
    "file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "\n",
    "# Construct the file path\n",
    "file_path = Path(output_dir) / f\"{symbol}-{chart_time}/{file_name}\"\n",
    "\n",
    "# Read the CSV file into a dataframe\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Iterate over the rows of the dataframe\n",
    "for i, row in df.iterrows():\n",
    "    try:\n",
    "        # Convert the 'open' column to float\n",
    "        open_value = float(row['open'])\n",
    "    except ValueError:\n",
    "        # Print the value that caused the error\n",
    "        print(row['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd8ede",
   "metadata": {},
   "source": [
    "## Rough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923237a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-18T14:15:33.137420Z",
     "start_time": "2023-01-18T14:15:33.131410Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over the symbols and chart times\n",
    "for symbol in symbols:\n",
    "    for chart_time in chart_times:\n",
    "        # Construct the file name\n",
    "        file_name = f\"{symbol}-{chart_time}.csv\"\n",
    "\n",
    "        # Construct the file path\n",
    "        file_path = Path(output_dir) / f\"{symbol}-{chart_time}-monthly_data/{file_name}\"\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408766c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
